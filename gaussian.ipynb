{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import open3d as o3d\n",
    "from chamferdist import ChamferDistance\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.chamfer import mahalanobis_distance_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate synthetic data\n",
    "N, D = 1000, 3  # number of points and dimenstinality\n",
    "\n",
    "if D == 2:\n",
    "    # set gaussian ceters and covariances in 2D\n",
    "    means = np.array([[0.5, 0.0], [0, 0], [-0.5, -0.5], [-0.8, 0.3]])\n",
    "    covs = np.array(\n",
    "        [\n",
    "            np.diag([0.01, 0.01]),\n",
    "            np.diag([0.025, 0.01]),\n",
    "            np.diag([0.01, 0.025]),\n",
    "            np.diag([0.01, 0.01]),\n",
    "        ]\n",
    "    )\n",
    "elif D == 3:\n",
    "    # set gaussian ceters and covariances in 3D\n",
    "    means = np.array(\n",
    "        [[0.5, 0.0, 0.0], [0.0, 0.0, 0.0], [-0.5, -0.5, -0.5], [-0.8, 0.3, 0.4]]\n",
    "    )\n",
    "    covs = np.array(\n",
    "        [\n",
    "            np.diag([0.01, 0.01, 0.03]),\n",
    "            np.diag([0.08, 0.01, 0.01]),\n",
    "            np.diag([0.01, 0.05, 0.01]),\n",
    "            np.diag([0.03, 0.07, 0.01]),\n",
    "        ]\n",
    "    )\n",
    "n_gaussians = means.shape[0]\n",
    "\n",
    "points = []\n",
    "for i in range(len(means)):\n",
    "    x = np.random.multivariate_normal(means[i], covs[i], N)\n",
    "    points.append(x)\n",
    "points = np.concatenate(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load point clouds\n",
    "\n",
    "# target cloud\n",
    "cloud_path = \"output/elbow/test/24102.pcd\"\n",
    "tgt_points = np.array(o3d.io.read_point_cloud(cloud_path).points)\n",
    "\n",
    "# source clouds\n",
    "files = os.listdir(\"output/elbow/test/\")\n",
    "# limit = 500\n",
    "limit = len(files)\n",
    "\n",
    "clouds = [x for x in files if x.endswith(\".pcd\")]\n",
    "src_points = []\n",
    "for i in range(limit):\n",
    "    src_points.append(\n",
    "        np.array(o3d.io.read_point_cloud(\"output/elbow/test/\" + clouds[i]).points)\n",
    "    )\n",
    "\n",
    "src_points = np.array(src_points)\n",
    "print(\"Number of source clouds: \", len(src_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#fit the gaussian model for a single cloud\n",
    "#gmm = GaussianMixture(n_components=n_gaussians, covariance_type='diag')\n",
    "gmm = GaussianMixture(n_components=128, covariance_type='full')\n",
    "gmm.fit(tgt_points)\n",
    "print(gmm.covariances_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit gaussian models for entire testset\n",
    "def fit_gaussians(points, n_gaussians):\n",
    "    means = []\n",
    "    covs = []\n",
    "    weights = []\n",
    "    for i in tqdm(range(len(points))):\n",
    "        gmm = GaussianMixture(n_components=n_gaussians, covariance_type=\"full\")\n",
    "        gmm.fit(points[i])\n",
    "        means.append(gmm.means_)\n",
    "        covs.append(gmm.covariances_)\n",
    "        weights.append(gmm.weights_)\n",
    "\n",
    "    return np.array(means), np.array(covs), np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [int(x.split(\".\")[0]) for x in clouds]\n",
    "\n",
    "means, covs, weights = fit_gaussians(src_points, 128)\n",
    "print(means.shape, covs.shape)\n",
    "with open(\"gaussians/gaussians_128.pkl\", \"wb\") as f:\n",
    "    pickle.dump([means, covs, ids, weights], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure mahalanobis distances from src clouds to the model\n",
    "limit = 100\n",
    "# limit = len(src_points)\n",
    "mahal_dists_pointwise = []\n",
    "for src in src_points[:limit]:\n",
    "    mahal_dists_pointwise.append(np.abs(gmm.score_samples(src)))\n",
    "\n",
    "mahal_dists_pointwise = np.array(mahal_dists_pointwise)\n",
    "mahal_dists_sk = np.sum(mahal_dists_pointwise, axis=1)\n",
    "print(mahal_dists_sk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute chamfer distance for comparison\n",
    "chamferDist = ChamferDistance()\n",
    "\n",
    "src_tensor = torch.from_numpy(np.float32(src_points)).cuda()\n",
    "tgt_tensor = torch.from_numpy(np.float32(tgt_points)).cuda()\n",
    "tgt_tensor = tgt_tensor.repeat(len(src_points), 1, 1)\n",
    "# print(src_tensor.shape, tgt_tensor.shape)\n",
    "\n",
    "chamfer_dists = chamferDist(\n",
    "    src_tensor[:limit], tgt_tensor[:limit], bidirectional=False, reduction=None\n",
    ")\n",
    "chamfer_dists = chamfer_dists.detach().cpu().numpy()\n",
    "print(chamfer_dists.shape)\n",
    "\n",
    "# # return point-wise distances for single source cloud\n",
    "# knn = chamferDist(\n",
    "#     src_tensor, tgt_tensor, return_nn=True, bidirectional=False, reduction=None\n",
    "# )\n",
    "# chamfer_dist = knn[0].dists[0].flatten().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot two distributions on same axis\n",
    "def plot_dists(mahal_dist_sk, maahal_dist_cust, chamfer_dist, title):\n",
    "    x = np.arange(0, len(mahal_dist_sk))\n",
    "\n",
    "    # scale chamfer distance to be comparable with mahalanobis\n",
    "    mahal_dist_max = np.max(mahal_dist_sk)\n",
    "    chamfer_dist_max = np.max(chamfer_dist)\n",
    "    chamfer_dist = chamfer_dist / chamfer_dist_max * mahal_dist_max\n",
    "\n",
    "    plt.figure(figsize=(30, 6))\n",
    "    plt.plot(x, mahal_dist_sk, label=\"mahalanobis_sklearn\")\n",
    "    plt.plot(x, maahal_dist_cust, label=\"mahalanobis_custom\")\n",
    "    plt.plot(x, chamfer_dist, label=\"chamfer\")\n",
    "\n",
    "    plt.xlabel(\"point cloud index\")\n",
    "    plt.ylabel(\"distance\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "# comparison of sklearn mahal distance and custom implementation\n",
    "mean = gmm.means_\n",
    "cov = gmm.covariances_\n",
    "mean, cov = torch.tensor(mean).cuda(), torch.tensor(cov).cuda()\n",
    "mean, cov = mean.repeat(len(src_points), 1, 1), cov.repeat(len(src_points), 1, 1, 1)\n",
    "print(mean.shape, cov.shape, src_tensor.shape)\n",
    "\n",
    "mahal_dists_custom = mahalanobis_distance_gmm(src_tensor[:limit], mean[:limit], cov[:limit])\n",
    "mahal_dists_custom = mahal_dists_custom.detach().cpu().numpy()\n",
    "mahal_dists_custom = mahal_dists_custom/2\n",
    "print(mahal_dists_custom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dists(\n",
    "    mahal_dists_sk, mahal_dists_custom, chamfer_dists, \"Mahalanobis vs Chamfer Distance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize\n",
    "# if D == 2:\n",
    "#     visualization.visualize_2D_gmm(\n",
    "#         points, gmm.weights_, gmm.means_.T, np.sqrt(gmm.covariances_).T\n",
    "#     )\n",
    "# elif D == 3:\n",
    "#     visualization.visualize_3d_gmm(\n",
    "#         points, gmm.weights_, gmm.means_.T, np.sqrt(gmm.covariances_).T\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

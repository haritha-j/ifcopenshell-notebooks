{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIM relationship detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for performing relationship detection using design files.\n",
    "\n",
    "#### Input:\n",
    "1. Design file structure extracted from navisworks NWD file.\n",
    "2. IFC file generated from NWD file\n",
    "3. graph predictions from GNN\n",
    "\n",
    "#### Sections:\n",
    "1. Relationship identification: Identify, extract and (visualize) \n",
    "aggregation and connectivity relationships.\n",
    "2. Visalization: Deprecated\n",
    "3. IFC to cloud: Create point clouds from each element in IFC file\n",
    "4. Graph dataset: Create a graph dataset from relationship information\n",
    " \n",
    " (GNN training available in link_prediction.ipynb notebook)\n",
    "5. Evaluate GNN: Evaluate predictions from GNN\n",
    "6. Visalize predictions: Draw IFC element to visualize FP,TP,FNs\n",
    "7. Analyze dataset and results: Repetition removal, element category analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import json\n",
    "import collections\n",
    "import math\n",
    "import uuid\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ifc and pointcloud\n",
    "import ifcopenshell\n",
    "import open3d as o3d\n",
    "import pymeshlab as ml\n",
    "from compas.geometry import oriented_bounding_box_numpy\n",
    "from scipy.spatial import distance\n",
    "from ifcopenshell.util.selector import Selector\n",
    "\n",
    "# graph \n",
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "\n",
    "from src.structure import get_systems, get_branches\n",
    "from src.visualisation import draw_relationship\n",
    "from src.geometry import element_distance, \n",
    "from src.cloud import element_to_cloud\n",
    "from src.graph import process_nodes, process_edges, IndustrialFacilityDataset\n",
    "\n",
    "# vis\n",
    "# from ipywidgets import interact\n",
    "# from OCC.Core.Bnd import Bnd_Box, Bnd_OBB\n",
    "# from OCC.Core.BRepBndLib import brepbndlib_AddOBB\n",
    "# from OCC.Core.BRepPrimAPI import (BRepPrimAPI_MakeBox, \n",
    "# BRepPrimAPI_MakeSphere, BRepPrimAPI_MakeCylinder)\n",
    "# from OCC.Core.gp import gp_Pnt, gp_XYZ, gp_Ax2, gp_Dir\n",
    "\n",
    "# from utils.JupyterIFCRenderer import JupyterIFCRenderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load design file structure\n",
    "\n",
    "system_dict_file = \"../EastDeckBox.nwd_aggregation.json\"\n",
    "system = 'East-DeckBox-Piping.rvm'\n",
    "\n",
    "#m = ifcopenshell.open(\"data/231110AC-11-Smiley-West-04-07-2007.ifc\")k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  aggrgegation relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_systems(system_dict_file)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topological relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branches = get_branches(system_dict_file)[system]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requisties for IFC file creation\n",
    "\n",
    "create_guid = lambda: ifcopenshell.guid.compress(uuid.uuid1().hex)\n",
    "m = ifcopenshell.open(\"../east_merged.ifc\")\n",
    "owner_history = m.by_type(\"IfcOwnerHistory\")[0]\n",
    "project = m.by_type(\"IfcProject\")[0]\n",
    "context = m.by_type(\"IfcGeometricRepresentationContext\")[0]\n",
    "floor = m.by_type(\"IfcBuildingStorey\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw links between connected elements, return connections\n",
    "def visualize_branches(branches, ifc, floor=None, owner_history=None, context=None, draw=False, contiguous=True, dist_thresh=0.002):\n",
    "    pipe_type = 'IFCPIPESEGMENT'\n",
    "    fitting_type = 'IFCPIPEFITTING'\n",
    "\n",
    "    pipe_selector = Selector()\n",
    "    fitting_selector = Selector()\n",
    "    pipes = pipe_selector.parse(ifc, '.' + pipe_type)\n",
    "    fittings = fitting_selector.parse(ifc, '.' + fitting_type)\n",
    "    fitting_names = [f.Name for f in fittings]\n",
    "    pipe_names = [p.Name for p in pipes]\n",
    "    print(pipes[0].Name)\n",
    "\n",
    "    vis_dict = {}\n",
    "    for k, val in branches.items():\n",
    "        vis_elements = []\n",
    "        connect = True\n",
    "        for element in val:\n",
    "            if element in pipe_names:\n",
    "                vis_elements.append((element, pipe_type, connect))\n",
    "                connect = True\n",
    "            elif element in fitting_names:\n",
    "                vis_elements.append((element, fitting_type, connect))\n",
    "                connect = True\n",
    "            else:\n",
    "                connect = False\n",
    "        vis_dict[k] = vis_elements\n",
    "\n",
    "    error_count = 0\n",
    "    count = 0\n",
    "    rels = []\n",
    "    selector = Selector()\n",
    "    \n",
    "    # enumerate through branches\n",
    "    for k, val in tqdm(vis_dict.items()):\n",
    "#         if count == 10:\n",
    "#             break\n",
    "        branch_size = len(val)\n",
    "        for i, element in enumerate(val):\n",
    "            #check if element is not the last element\n",
    "            if (i+1) < branch_size:\n",
    "                try:\n",
    "                    \n",
    "                    if val[i+1][2] or not contiguous:\n",
    "                        rels.append([(element[0], element[1]), \n",
    "                                  (val[i+1][0], val[i+1][1])])\n",
    "                        if draw:\n",
    "                            element1 = selector.parse(\n",
    "                                m, '.' + element[1] + '[Name *= \"' + element[0] + '\"]')[0]\n",
    "                            element2 = selector.parse(\n",
    "                                m, '.' + val[i+1][1] + '[Name *= \"' + val[i+1][0] + '\"]')[0]\n",
    "                            draw_relationship(element[0], element1, \n",
    "                                  val[i+1][0], element2, ifc, floor, owner_history, context)\n",
    "                \n",
    "                    else:\n",
    "                        element1 = selector.parse(\n",
    "                            m, '.' + element[1] + '[Name *= \"' + element[0] + '\"]')[0]\n",
    "                        element2 = selector.parse(\n",
    "                            m, '.' + val[i+1][1] + '[Name *= \"' + val[i+1][0] + '\"]')[0]\n",
    "                        \n",
    "                        if element_distance(element1, element2, ifc) < dist_thresh:\n",
    "                            rels.append([(element[0], element[1]), \n",
    "                                  (val[i+1][0], val[i+1][1])])\n",
    "                            if draw:\n",
    "                                draw_relationship(element[0], element1, \n",
    "                                  val[i+1][0], element2, ifc, floor, owner_history, context)\n",
    "                except Exception as e:\n",
    "                    #print (e)\n",
    "                    error_count +=1\n",
    "        count +=1\n",
    "\n",
    "    print(error_count)\n",
    "    return rels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rels = visualize_branches(branches, m, floor, owner_history, context, True)\n",
    "# rels = visualize_branches(branches, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rels), rels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../top_rels_eastdeckbox_test.pkl', 'wb') as f:\n",
    "    pickle.dump(rels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.write('../east_vis_test.ifc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# viewer = JupyterIFCRenderer(m, size=(400,300))\n",
    "# viewer.setAllTransparent()\n",
    "# viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aggregation relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picker = viewer.colorPicker()\n",
    "# picker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_dict = {'HVAC':['Rohrtypen:Kupfer - Hartgelötet:7718868', 'Rohrtypen:Kupfer - Hartgelötet:7718886', ],\n",
    "#            'electrical':[ 'Rohrtypen:Kupfer - Hartgelötet:7718872', 'Rohrtypen:Kupfer - Hartgelötet:7718880']}\n",
    "\n",
    "# # PAINT A SET OF ELEMENTS IN ONE COLOUR\n",
    "# def systemSelect(system):\n",
    "#     selector = Selector()\n",
    "#     for e in out_dict[system]:\n",
    "#         element = selector.parse(m, '.IfcProduct[Name *= \"' + e + '\"]')[0]\n",
    "#         viewer.setColor(element, picker.value)\n",
    "#     return system\n",
    "\n",
    "# interact(systemSelect, system=['HVAC', 'electrical'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instances of building elements with represenations can be selected interactivly. Information such as the attributes `GUID`, `Name` etc. are displayed to the left of the 3D viewport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reset colours\n",
    "# viewer.setDefaultColors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topological relationships\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replace jupyter renderer\n",
    "\n",
    "1. Compute the bounding box of ifc product directly from points\n",
    "2. generate ifc elements to indicate relationships\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "# element_name = \"TUBE 1 of BRANCH /AM-8120227-WD-MDA-01/B1\"\n",
    "# element_type = \"IFCPIPESEGMENT\"\n",
    "\n",
    "# selector = Selector()\n",
    "# element = selector.parse(\n",
    "#     m, '.' + element_type + '[Name *= \"' + element_name + '\"]')[0]\n",
    "\n",
    "# shape = element.Representation.Representations[0].Items[0]\n",
    "# element_coords = np.array(shape.Coordinates.CoordList)\n",
    "# #print(element_coords)\n",
    "# bbox = oriented_bounding_box_numpy(element_coords)\n",
    "# print(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "# element1_name = \"TUBE 1 of BRANCH /AM-8120227-WD-MDA-01/B1\"\n",
    "# element1_type = \"IFCPIPESEGMENT\"\n",
    "# element2_name = \"ELBOW 1 of BRANCH /AM-8120227-WD-MDA-01/B1\"\n",
    "# element2_type = \"IFCPIPEFITTING\"\n",
    "\n",
    "# element3_name = \"TUBE 2 of BRANCH /AM-8120227-WD-MDA-01/B1\"\n",
    "# element3_type = \"IFCPIPESEGMENT\"\n",
    "# element4_name = \"ELBOW 2 of BRANCH /AM-8120227-WD-MDA-01/B1\"\n",
    "# element4_type = \"IFCPIPEFITTING\"\n",
    "# element5_name = \"TUBE 3 of BRANCH /AM-8120227-WD-MDA-01/B1\"\n",
    "# element5_type = \"IFCPIPESEGMENT\"\n",
    "\n",
    "# draw_relationship(element1_name, element1_type, \n",
    "#                   element2_name, element2_type, m)\n",
    "# draw_relationship(element2_name, element2_type, \n",
    "#                   element3_name, element3_type, m)\n",
    "# draw_relationship(element3_name, element3_type, \n",
    "#                   element4_name, element4_type, m)\n",
    "# draw_relationship(element4_name, element4_type, \n",
    "#                   element5_name, element5_type, m)\n",
    "#element1_center, element1_coords = get_element_deets()\n",
    "\n",
    "\n",
    "\n",
    "# centerpoint =gp_Pnt(element1_center)\n",
    "# ball = BRepPrimAPI_MakeSphere(centerpoint, 0.02).Shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element.Representation.Representations[0].Items[0].CoordIndex = element.Representation.Representations[0].Items[0].CoordIndex[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IFC to cloud\n",
    "\n",
    "sample points from ifc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifc = ifcopenshell.open(\"../east_merged.ifc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_type = 'IFCPIPESEGMENT'\n",
    "selector = Selector()\n",
    "tees = selector.parse(ifc, '.' + element_type)\n",
    "print(len(tees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, element in tqdm(enumerate(tees)):\n",
    "    save_path = \"../east_tee_clouds_test/\" + str(i) + \".ply\"\n",
    "    cloud = element_to_cloud(element, save_path, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get nodes & edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['FLANGE', 'ELBOW', 'TEE', 'TUBE', 'BEND']\n",
    "node_info = process_nodes(ifc, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(node_info), len(node_info[0]), len(node_info[1]))\n",
    "\n",
    "with open('../nodes_eastdeckbox_test.pkl', 'wb') as f:\n",
    "    pickle.dump(node_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../top_rels_eastdeckbox.pkl', 'rb') as f:\n",
    "    rels = pickle.load(f)\n",
    "with open('../nodes_eastdeckbox.pkl', 'rb') as f:\n",
    "    node_info = pickle.load(f)\n",
    "    nodes = node_info[0]\n",
    "    \n",
    "edges = process_edges(ifc, nodes, rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../edges_eastdeckbox_test.pkl', 'wb') as f:\n",
    "    pickle.dump(edges, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "\n",
    "# print(points.shape, labels.shape, centers.shape, lengths.shape, directions.shape)\n",
    "# print(points[0][0], labels[0], centers[0], lengths[0], directions[0])\n",
    "# print(5 in labels)\n",
    "\n",
    "# edges_src = edges[:,0]\n",
    "# edges_dst = edges[:,1]\n",
    "# print(edges_src)\n",
    "# print(np.max(edges_dst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IndustrialFacilityDataset()\n",
    "graph = dataset[0]\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load edges\n",
    "with open('../eval/pos_edges_test.pkl', 'rb') as f:\n",
    "            u, v = pickle.load(f)\n",
    "with open('../eval/neg_edges_test.pkl', 'rb') as f:\n",
    "            neg_u_full,neg_v_full = pickle.load(f)\n",
    "print(len(neg_u_full), len(u))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load predicted scores\n",
    "with open('../eval/pos_score_test.pkl', 'rb') as f:\n",
    "            pos_score = pickle.load(f)\n",
    "with open('../eval/neg_score_test.pkl', 'rb') as f:\n",
    "            neg_score= pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(neg_score), len(pos_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate confusion matrix coefficiants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "FNs, TPs, FPs, TNs = [], [], [], []\n",
    "\n",
    "# TPs / FNs\n",
    "for i, score in enumerate(pos_score):\n",
    "    sig = 1/(1 + np.exp(-score))\n",
    "    if sig > threshold:\n",
    "        TPs.append([u[i].item(), v[i].item()])\n",
    "    else:\n",
    "        FNs.append([u[i].item(), v[i].item()])\n",
    "\n",
    "# FPs\n",
    "for i, score in tqdm(enumerate(neg_score)):\n",
    "    sig = 1/(1 + np.exp(-score))\n",
    "    if sig > threshold:\n",
    "        FPs.append([neg_u_full[i], neg_v_full[i]])\n",
    "\n",
    "print(len(TPs), len(FPs), len(FNs) )\n",
    "TPs = np.array(TPs)\n",
    "FPs = np.array(FPs)\n",
    "FNs = np.array(FNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1/(1 + np.exp(-neg_score[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../eval/metrics_test.pkl', 'wb') as f:\n",
    "    pickle.dump([TPs, FPs, FNs], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../eval/metrics_test.pkl', 'rb') as f:\n",
    "    TPs, FPs, FNs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate raw metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = len(TPs)/(len(TPs)+len(FPs))\n",
    "recall = len(TPs)/(len(TPs)+len(FNs))\n",
    "accuracy = (len(TPs)-len(FPs) +len(neg_score))/(len(neg_score)+len(pos_score))\n",
    "print(precision, recall, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refinement based on element distances (eliminate predictions beyond a distance threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'eastdeckbox'\n",
    "data_path = '../'\n",
    "node_file = \"nodes_\" + site + \".pkl\"\n",
    "with open(data_path + node_file, 'rb') as f:\n",
    "    node_info = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if positive predictions fall within distance threshold\n",
    "def check_predictions(preds, point_info, dist_thresh=0.002):\n",
    "    refined_preds = []\n",
    "    \n",
    "    for pair in tqdm(preds):\n",
    "        dist = np.min(distance.cdist(\n",
    "            point_info[pair[0]], point_info[pair[1]], 'sqeuclidean'))\n",
    "        if (dist < dist_thresh):\n",
    "            refined_preds.append(pair)\n",
    "    return refined_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_TPs = check_predictions(TPs, node_info[1])\n",
    "refined_FPs = check_predictions(FPs, node_info[1])\n",
    "\n",
    "print(len(refined_TPs), len(refined_FPs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../eval/refined_test.pkl', 'wb') as f:\n",
    "    pickle.dump([refined_TPs, refined_FPs], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../eval/refined.pkl', 'rb') as f:\n",
    "    refined_TPs, refined_FPs = pickle.load(f)\n",
    "print(len(refined_TPs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refined metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = len(refined_TPs)/(len(refined_TPs)+len(refined_FPs))\n",
    "recall = len(refined_TPs)/(len(refined_TPs)+len(FNs))\n",
    "accuracy = (len(refined_TPs)-len(refined_FPs) +len(neg_score))/(len(neg_score)+len(pos_score))\n",
    "print(precision, recall, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score= pos_score[:int(len(pos_score)/10)]\n",
    "neg_score= pos_score[:int(len(neg_score)/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.concatenate([pos_score, neg_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = 1/(1 + np.exp(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "RocCurveDisplay.from_predictions(labels, scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifc = ifcopenshell.open(\"../east_merged.ifc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_guid = lambda: ifcopenshell.guid.compress(uuid.uuid1().hex)\n",
    "owner_history = ifc.by_type(\"IfcOwnerHistory\")[0]\n",
    "project = ifc.by_type(\"IfcProject\")[0]\n",
    "context = ifc.by_type(\"IfcGeometricRepresentationContext\")[0]\n",
    "floor = ifc.by_type(\"IfcBuildingStorey\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = ifc.createIfcColourRgb('red', Red=0.9, Green=0.0, Blue=0.0)\n",
    "green = ifc.createIfcColourRgb('green', Red=0.0, Green=0.9, Blue=0.0)\n",
    "yellow = ifc.createIfcColourRgb('yellow', Red=0.9, Green=0.9, Blue=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize results on ifc file\n",
    "def draw_predictions(preds, nodes, ifc, colour):\n",
    "    for pair in tqdm(preds):\n",
    "        element1 = ifc.by_id(nodes[pair[0]][4])\n",
    "        element1_name = element1.Name\n",
    "        element2 = ifc.by_id(nodes[pair[1]][4])\n",
    "        element2_name = element2.Name\n",
    "        \n",
    "        draw_relationship(element1_name, element1, element2_name, \n",
    "                          element2, ifc, floor, owner_history, context, colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_predictions(refined_TPs, node_info[0], ifc, green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_predictions(refined_FPs, node_info[0], ifc, yellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_predictions(FNs, node_info[0], ifc, red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifc.write('../eval/pred_vis_test.ifc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional refinements\n",
    "\n",
    "### remove repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the graph is bidirected, a single edge has two predictions. \n",
    "# This function removes repetitions in a single set of predictions.\n",
    "def remove_repetitions(preds):\n",
    "    non_rep = []\n",
    "    for i, pair in tqdm(enumerate(preds)):\n",
    "        found = False\n",
    "        for j, pair2 in enumerate(preds[i:]):\n",
    "            if pair[0] == pair2[1] and pair[1] == pair2[0]:\n",
    "                found = True\n",
    "                #break\n",
    "        if not found:\n",
    "            non_rep.append(pair)\n",
    "    \n",
    "    return non_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above, except for removing repetitions across two sets of predictions\n",
    "# ex. between true positives and false negatives\n",
    "def compare_preds(preds1, preds2):\n",
    "    for i in range(len(preds1)):\n",
    "        preds1[i].sort()\n",
    "    for i in range(len(preds2)):\n",
    "        preds2[i].sort()\n",
    "    non_rep = []\n",
    "    \n",
    "    for i, pair in enumerate(preds1):\n",
    "        found = False\n",
    "        for j, pair2 in enumerate(preds2):\n",
    "            if pair[0] == pair2[0] and pair[1] == pair2[1]:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            non_rep.append(pair)\n",
    "    \n",
    "    return non_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(refined_TPs))\n",
    "non_rep_TPs = remove_repetitions(refined_TPs)\n",
    "print(len(non_rep_TPs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(refined_FPs))\n",
    "non_rep_FPs = remove_repetitions(refined_FPs)\n",
    "print(len(non_rep_FPs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(FNs))\n",
    "non_rep_FNs = remove_repetitions(FNs)\n",
    "print(len(non_rep_FNs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_FNs = compare_preds(non_rep_FNs, non_rep_TPs)\n",
    "print(len(non_rep_FNs), len(refined_FNs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refined metrics after removing repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = len(non_rep_TPs)/(len(non_rep_TPs)+len(non_rep_FPs))\n",
    "recall = len(non_rep_TPs)/(len(non_rep_TPs)+len(non_rep_FNs))\n",
    "accuracy = (len(non_rep_TPs)-len(refined_FPs) +len(neg_score))/(len(neg_score)+len(pos_score))\n",
    "print(precision, recall, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../eval/east_non_rep_test.pkl', 'wb') as f:\n",
    "    pickle.dump([non_rep_TPs, non_rep_FPs, non_rep_FNs], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate metrics for each element category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse dataset and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element type wise precision recall analysis\n",
    "def sort_type(preds, nodes):\n",
    "    bins = np.zeros([4,4])\n",
    "    for p in preds:\n",
    "        x=nodes[p[0]][0]\n",
    "        y= nodes[p[1]][0]\n",
    "        if x == 4:\n",
    "          x = 3\n",
    "        if y == 4:\n",
    "          y = 3\n",
    "        li = [x,y]\n",
    "        li.sort()\n",
    "        x,y = li[0],li[1]\n",
    "        \n",
    "        bins[x][y] += 1\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_bins = sort_type(non_rep_TPs,node_info[0] )\n",
    "fp_bins = sort_type(non_rep_FPs,node_info[0] )\n",
    "fn_bins = sort_type(non_rep_FNs,node_info[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tp_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = tp_bins/(tp_bins+fn_bins)\n",
    "precision = tp_bins/(tp_bins+fp_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1:\", (2*precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate element types in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse dataset\n",
    "\n",
    "# load data\n",
    "site = 'east'\n",
    "\n",
    "def analyse_dataset(site):\n",
    "  data_path = \"/content/drive/MyDrive/graph/\"\n",
    "  edge_file = \"edges_\" + site + \"deckbox.pkl\"\n",
    "  node_file = \"nodes_\" + site + \"deckbox.pkl\"\n",
    "  with open(data_path + node_file, 'rb') as f:\n",
    "      node_info = pickle.load(f)\n",
    "  with open(data_path + edge_file, 'rb') as f:\n",
    "      edges = pickle.load(f)\n",
    "\n",
    "  # get element type counts\n",
    "  labels = np.array([i[0] for i in node_info[0]])\n",
    "  unique, counts = np.unique(labels, return_counts=True)\n",
    "  print(dict(zip(unique, counts)))\n",
    "\n",
    "  # get connection counts\n",
    "  counts = np.zeros((5,5), dtype=int)\n",
    "\n",
    "  for edge in edges:\n",
    "    x = labels[edge[0]]\n",
    "    y = labels[edge[1]]\n",
    "    if x == 4:\n",
    "      x = 3\n",
    "    if y == 4:\n",
    "      y = 3\n",
    "    li = [x,y]\n",
    "    li.sort()\n",
    "    x,y = li[0],li[1]\n",
    "    counts[x][y] += 1\n",
    "\n",
    "  return(counts)\n",
    "\n",
    "c_east = analyse_dataset('east')\n",
    "c_west = analyse_dataset('west')\n",
    "count = c_east + c_west\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

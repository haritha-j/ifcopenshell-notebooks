{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c41916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import uuid\n",
    "import ifcopenshell\n",
    "from ifcopenshell import template\n",
    "\n",
    "from src.visualisation import *\n",
    "\n",
    "#create_guid = lambda: ifcopenshell.guid.compress(uuid.uuid1().hex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7193f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254db9ec",
   "metadata": {},
   "source": [
    "### CLOI Dataset Creation\n",
    "\n",
    "The following section converts CLOI scans into a pcd dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c829d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine clouds\n",
    "data_path = \"/mnt/f/datasets/export/export/\"\n",
    "max_points = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed33839",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = os.listdir(data_path)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d33efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = []\n",
    "element_count = 0\n",
    "error_count = 0\n",
    "for i, cl in enumerate(classes):\n",
    "    all_elements = []\n",
    "    class_path = data_path + cl\n",
    "    elements = os.listdir(class_path)\n",
    "    for j, el in tqdm(enumerate(elements)):\n",
    "        try:\n",
    "            element = np.loadtxt(class_path + '/' + el)\n",
    "\n",
    "            # downsample\n",
    "            if (len(element) > 0 and element.ndim == 2 and element.shape[1] == 4):\n",
    "                if len(element)  > max_points:\n",
    "                    #idx = np.random.randint(element.shape[0], size=max_points)\n",
    "                    #element = element[idx :]\n",
    "                    element = np.random.permutation(element)[:max_points]\n",
    "\n",
    "                element = np.delete(element, 3, axis=1) # remove point index\n",
    "                element = np.insert(element, 3, values=[element_count], axis=1) # add element index\n",
    "                #print(element.shape)\n",
    "                element_count += 1\n",
    "                all_elements.append(element)\n",
    "        except Exception as E:\n",
    "            error_count += 1\n",
    "            \n",
    "            \n",
    "    all_elements = np.vstack(all_elements)\n",
    "    all_elements = np.insert(all_elements, 4, values=[i], axis=1) # add class index\n",
    "    all_classes.append(all_elements)\n",
    "    \n",
    "all_classes = np.concatenate(all_classes)\n",
    "print(all_classes.shape)\n",
    "print (\"errors: \", error_count)\n",
    "        \n",
    "        #print(points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10faefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.t.geometry.PointCloud()\n",
    "points = all_classes[:,0:3]\n",
    "el_index  = [[i] for i in all_classes[:,3]]\n",
    "cl_index  = [[i] for i in all_classes[:,4]]\n",
    "\n",
    "\n",
    "pcd.point[\"positions\"] = o3d.core.Tensor(points)\n",
    "pcd.point[\"elements\"] = o3d.core.Tensor(el_index)\n",
    "pcd.point[\"classes\"] = o3d.core.Tensor(cl_index)\n",
    "\n",
    "o3d.t.io.write_point_cloud(\"water2.pcd\", pcd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36616a89",
   "metadata": {},
   "source": [
    "## Pipe parameter detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4f2162",
   "metadata": {},
   "source": [
    "### Generation of synethetic IFC element dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eccd0d9",
   "metadata": {},
   "source": [
    "#### dataset creation process\n",
    "1. Generate params for element model\n",
    "2. Generate ifc models\n",
    "4. Convert to obj models using ifcConvert (ifc2obj.py script)\n",
    "3. Convert to partially occluded EXR images using render_depth.py script\n",
    "4. Covnert to point clouds using process_exr.py script\n",
    "5. Combine multiple views of object to create training and testing datasets\n",
    "\n",
    "\n",
    "##### Step 1 & 2. IFC model generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d51aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "density = 1024\n",
    "sample_size = 256\n",
    "config_path = \"config/pipeline.json\"\n",
    "pcd_path = \"/home/haritha/downloads/blender-2.79-linux-glibc219-x86_64/output/pcd/\"\n",
    "blueprint = 'data/sample.ifc'\n",
    "num_scans = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "elbow - modelled as an IfcRevolvedAreaSolid \n",
    "\n",
    "params:\n",
    "position - 3D coordinate\n",
    "axis_direction - 3D vector, axis of revolution (z>=0)\n",
    "axis_position - 3D coordinate\n",
    "angle - angle of revolution (0 -> pi)\n",
    "radius\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856094b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pipe - modelled as an IfcExtrudedAreaSolid\n",
    "\n",
    "params:\n",
    "position - 3D coordinate\n",
    "extrusion_direction - 3D vector (z>=0)\n",
    "length - 3D coordinate\n",
    "radius\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea66297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new blank ifc file\n",
    "def setup_ifc_file(blueprint):\n",
    "\n",
    "    ifc = ifcopenshell.open(blueprint)\n",
    "    ifcNew = ifcopenshell.file(schema=ifc.schema)\n",
    "    \n",
    "    owner_history = ifc.by_type(\"IfcOwnerHistory\")[0]\n",
    "    project = ifc.by_type(\"IfcProject\")[0]\n",
    "    context = ifc.by_type(\"IfcGeometricRepresentationContext\")[0]\n",
    "    floor = ifc.by_type(\"IfcBuildingStorey\")[0]\n",
    "    \n",
    "    ifcNew.add(project) \n",
    "    ifcNew.add(owner_history) \n",
    "    ifcNew.add(context) \n",
    "    ifcNew.add(floor)\n",
    "\n",
    "    return ifcNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761a884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate IfcBeam from parameters\n",
    "def create_IfcPipe(r, l, d, p, ifc, ifc_info):\n",
    "    cross_section = Circle_Section(r=r, ifcfile=ifc)\n",
    "    green = ifc.createIfcColourRgb('green', Red=0.0, Green=0.9, Blue=0.0)\n",
    "\n",
    "    beam = CreateBeam(ifc, container=ifc_info['floor'], name=\"pipe\", \n",
    "                      section=cross_section, L=l, position=p,\n",
    "                      direction=d, owner_history=ifc_info[\"owner_history\"],\n",
    "                      context=ifc_info[\"context\"], colour=green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return axis aligned bbox of pipe\n",
    "def pipe_bbox(r, l, d):\n",
    "    l_xz = math.sqrt(d[0]*d[0]+d[2]*d[2])\n",
    "    l_yz = math.sqrt(d[1]*d[1]+d[2]*d[2])\n",
    "    l_xy = math.sqrt(d[0]*d[0]+d[1]*d[1])\n",
    "    \n",
    "    cos_y = 0 if l_xz == 0 else l_xz/(math.sqrt(l_xz*l_xz + d[1]*d[1]))\n",
    "    sin_y = 0 if d[1] == 0 else d[1]/(math.sqrt(l_xz*l_xz + d[1]*d[1]))    \n",
    "    cos_x = 0 if l_yz == 0 else l_yz/(math.sqrt(l_yz*l_yz + d[0]*d[0]))\n",
    "    sin_x = 0 if d[0] == 0 else d[0]/(math.sqrt(l_yz*l_yz + d[0]*d[0]))    \n",
    "    cos_z = 0 if l_xy == 0 else l_xy/(math.sqrt(l_xy*l_xy + d[2]*d[2]))\n",
    "    sin_z = 0 if d[2] == 0 else d[2]/(math.sqrt(l_xy*l_xy + d[2]*d[2]))    \n",
    "\n",
    "    y = r*cos_y*2 + l*sin_y\n",
    "    x = r*cos_x*2 + l*sin_x\n",
    "    z = r*cos_z*2 + l*sin_z\n",
    "    \n",
    "    return (x,y,z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61475d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random synthetic pipe\n",
    "def create_pipe(config,  ifc, ifc_info):\n",
    "    # generate parameters\n",
    "    r = random.uniform(config['radius_range'][0], config['radius_range'][1])\n",
    "    l = random.uniform(config['length_range'][0], config['length_range'][1])\n",
    "    \n",
    "    d = []\n",
    "    for ax in config['extrusion_direction_range']:\n",
    "        d.append(random.uniform(ax[0], ax[1]))\n",
    "    d_np = np.array(d)\n",
    "    d = (d_np/np.linalg.norm(d_np)).tolist()\n",
    "\n",
    "    p = []\n",
    "    for coord in config['coordinate_range']:\n",
    "        p.append(random.uniform(coord[0], coord[1]))\n",
    "        \n",
    "    # normalize bbox\n",
    "    bbox = pipe_bbox(r,l,d)\n",
    "    bbox_l2 = math.sqrt(bbox[0]*bbox[0] + bbox[1]*bbox[1] + bbox[2]*bbox[2])\n",
    "    r, l = 10000*r/bbox_l2, 10000*l/bbox_l2\n",
    "    print(bbox_l2)\n",
    "    #bbox2 = pipe_bbox(r,l,d)\n",
    "    #print(bbox, bbox2, (bbox2[0]*bbox2[0] + bbox2[1]*bbox2[1] + bbox2[2]*bbox2[2]))\n",
    "\n",
    "    # center the element\n",
    "    centerpoint = [(p[i] + (l*d[i])/2) for i in range(3)]\n",
    "    p = [p[i] - centerpoint[i] for i in range(3)]\n",
    "    #print('c', p)\n",
    "    \n",
    "    #print(r,l,d,p)\n",
    "    \n",
    "    create_IfcPipe(r, l, d, p, ifc, ifc_info)\n",
    "    metadata = {'radius':r, \"direction\":d, \"length\":l, \"position\":p}\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773fce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_dataset(config, sample_size, element_class, output_base, blueprint, start=0):\n",
    "    # setup\n",
    "    f = open(config, 'r')\n",
    "    config_data  = json.load(f)\n",
    "    output_dir = os.path.join(output_base, element_class)\n",
    "    #os.makedirs(output_dir)\n",
    "\n",
    "    metadata = {}\n",
    "    for i in tqdm(range(start, sample_size+start)):\n",
    "        # generate ifc file\n",
    "        ifc = setup_ifc_file(blueprint)\n",
    "        owner_history = ifc.by_type(\"IfcOwnerHistory\")[0]\n",
    "        project = ifc.by_type(\"IfcProject\")[0]\n",
    "        context = ifc.by_type(\"IfcGeometricRepresentationContext\")[0]\n",
    "        floor = ifc.by_type(\"IfcBuildingStorey\")[0]\n",
    "        \n",
    "        ifc_info = {\"owner_history\": owner_history,\n",
    "            \"project\": project,\n",
    "           \"context\": context, \n",
    "           \"floor\": floor}\n",
    "        \n",
    "        # generate ifc element\n",
    "        if element_class == 'pipe':\n",
    "            e = create_pipe(config_data[element_class], ifc, ifc_info)\n",
    "            try:\n",
    "                geometries = ifc.by_id(0)\n",
    "                print(i)\n",
    "                #print(i, e, geometries)\n",
    "                print( geometries)\n",
    "        \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        metadata[str(i)] = e\n",
    "        ifc.write(os.path.join(output_dir, '%d.ifc' % i))\n",
    "    \n",
    "    with open(os.path.join(output_dir, 'metadata.json'), 'w') as f:\n",
    "        json.dump(metadata, f)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b080190c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "synthetic_dataset(config_path, sample_size, \"pipe\", 'output', blueprint, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d2009b",
   "metadata": {},
   "source": [
    "*Use external scripts to convert above IFC dataset into ocluded PCD dataset. (step 3, 4 & 5)*\n",
    "\n",
    "##### Step 6. Test / train dataset creation\n",
    "\n",
    "1. merge multiple views\n",
    "2. sample to standard density\n",
    "3. generate training and testing dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eadd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_resample_cloud(points, density):\n",
    "    indices = np.arange(points.shape[0])\n",
    "    if (len(points) > density):\n",
    "        sampled_indices = np.random.choice(indices, density, replace=False)\n",
    "    else:\n",
    "        sampled_indices = np.random.choice(indices, density, replace=True)\n",
    "        \n",
    "    #print(len(sampled_indices))\n",
    "    return(points[sampled_indices])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e39290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cloud(points, output_base, name):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    save_path = os.path.join(output_base, name + \".pcd\")\n",
    "    o3d.io.write_point_cloud(save_path, pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_merged_dataset(pcd_path, output_base, element_class, num_scans, density, num_views=3, test_split=0.1):\n",
    "    # load data\n",
    "    metadata_file = os.path.join(output_base, element_class, 'metadata.json')\n",
    "    f = open(metadata_file, 'r')\n",
    "    metadata = json.load(f)\n",
    "    \n",
    "    scans = os.listdir(pcd_path)\n",
    "    unique_files = set()\n",
    "    for sc in scans:\n",
    "        element = int(sc.split('_')[0])\n",
    "        unique_files.add(element)\n",
    "    \n",
    "    # merge multiple views\n",
    "    count = 0\n",
    "    metadata_new = {}\n",
    "    train_clouds = {}\n",
    "    test_clouds = {}\n",
    "    test_point = int(len(unique_files)*(1-test_split))\n",
    "    print(test_point)\n",
    "    for k, un in enumerate(unique_files):\n",
    "        for i in range(num_scans-num_views):\n",
    "            points = []\n",
    "            for j in range(num_views):\n",
    "                file_path = os.path.join(pcd_path, (str(un) + '_' + str(j) + '.pcd'))\n",
    "                pcd = o3d.io.read_point_cloud(file_path)\n",
    "                points.append(pcd.points)               \n",
    "\n",
    "            #merged.points = o3d.utility.Vector3dVector(np.vstack(points))\n",
    "            merged_points = np.vstack(points)\n",
    "            metadata_new[str(count)] = metadata[str(un)]\n",
    "            \n",
    "            if k < test_point:\n",
    "                train_clouds[str(count)] = merged_points\n",
    "            else:\n",
    "                test_clouds[str(count)] = merged_points\n",
    "                \n",
    "            count += 1\n",
    "\n",
    "    # resample and save_data\n",
    "    test_path = os.path.join(output_base, element_class, 'test')\n",
    "    train_path = os.path.join(output_base, element_class, 'train')\n",
    "    try:\n",
    "        os.mkdir(test_path)\n",
    "        os.mkdir(train_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for k in train_clouds.keys():\n",
    "        sampled_points = random_resample_cloud(train_clouds[k], density)\n",
    "        save_cloud(sampled_points, train_path, k)\n",
    "        \n",
    "    for k in test_clouds.keys():\n",
    "        sampled_points = random_resample_cloud(test_clouds[k], density)\n",
    "        save_cloud(sampled_points, test_path, k)\n",
    "\n",
    "    with open(os.path.join(output_base, element_class, 'metadata_new.json'), 'w') as f:\n",
    "        json.dump(metadata_new, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75922f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_merged_dataset(pcd_path, 'output', 'pipe', num_scans, density, 3, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e410f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b7c358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

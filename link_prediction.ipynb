{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRX0fNk4ObZo"
   },
   "source": [
    "\n",
    "Relationship Prediction\n",
    "===========================================\n",
    "\n",
    "Notebook for training and inference of element connectivity prediction using GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzV-X6jJObZk"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifRsGSMuObZq"
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import math\n",
    "from pathlib import Path\n",
    "import scipy.sparse as sp\n",
    "#from google.colab import drive\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.graph import get_edges_from_node_info_np, IndustrialFacilityDataset\n",
    "from src.geometry import sq_dist_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f05yJmDObZq"
   },
   "source": [
    "### Load graph dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "039Csi_hW9yX"
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "\n",
    "#model_path = '/content/drive/MyDrive/graph/'\n",
    "model_path = 'gnn_params/'\n",
    "model_name = \"model_4sage_3mlp.pth\"\n",
    "pred_name = \"pred_4sage_3mlp.pth\"\n",
    "data_path = \"/mnt/c/data/3D_CAD/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUYGNHzduB0E"
   },
   "outputs": [],
   "source": [
    "types = ['FLANGE', 'ELBOW', 'TEE', 'TUBE', 'BEND']\n",
    "np.random.seed(42)\n",
    "test_mode = False\n",
    "use_params = True\n",
    "create_pseudo_graph = True\n",
    "pseudo_graph_dist_thresh = 0.5\n",
    "negative_sampling_ratio = 1\n",
    "device = torch.device(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdY9VscEuNM-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not test_mode:\n",
    "    path = Path('output/west_ref/')\n",
    "    sitename = 'west'\n",
    "    dataset = IndustrialFacilityDataset(data_path, \"westdeckbox_ref\", use_params, path, sitename)\n",
    "else:\n",
    "    path = Path('output/east_ref/')\n",
    "    sitename = 'east'\n",
    "    dataset = IndustrialFacilityDataset(data_path, \"eastdeckbox\", use_params, path, sitename)\n",
    "g = dataset[0]\n",
    "g = g.to(device)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pseudo graph generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a pseudo graph whose edges depict nodes that are within a distance threshold\n",
    "def generate_pseudo_graph(nodes, dist_thresh=0.5):\n",
    "    print(len(nodes)**2)\n",
    "    nodes_cpu = nodes.cpu().numpy()\n",
    "    pseudo_edges = []\n",
    "    for i, n0 in enumerate(tqdm(nodes_cpu)):\n",
    "        for j, n1 in enumerate(nodes_cpu):\n",
    "            \n",
    "            if i >=j:\n",
    "                continue\n",
    "                \n",
    "            #rough distance check using two edges\n",
    "            bb0 = get_edges_from_node_info_np(n0)\n",
    "            bb1 = get_edges_from_node_info_np(n1)\n",
    "            if ((sq_dist_vect(bb0[0], bb1[0]) < dist_thresh) or\n",
    "                (sq_dist_vect(bb0[0], bb1[1]) < dist_thresh) or\n",
    "                (sq_dist_vect(bb0[1], bb1[0]) < dist_thresh) or\n",
    "                (sq_dist_vect(bb0[1], bb1[1]) < dist_thresh)):\n",
    "                \n",
    "                pseudo_edges.append((i,j))\n",
    "\n",
    "    return pseudo_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_pseudo_graph:\n",
    "    pseudo_edges = generate_pseudo_graph(g.ndata['feat'], pseudo_graph_dist_thresh)\n",
    "    \n",
    "    with open(model_path + '/pseudo_graph_' + sitename + str(pseudo_graph_dist_thresh) + '.pkl', 'wb') as f:\n",
    "        pickle.dump(pseudo_edges, f)\n",
    "\n",
    "else:\n",
    "    with open(model_path + '/pseudo_graph_' + sitename + str(pseudo_graph_dist_thresh) + '.pkl', 'rb') as f:\n",
    "       pseudo_edges = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_mode:\n",
    "    # remove real edges and add pseudo edges for testing\n",
    "    # TODO: compare the pseudo edges vs. real edges\n",
    "    print(g.number_of_edges(), len(pseudo_edges))\n",
    "    eids = np.arange(g.number_of_edges())\n",
    "    g_test = dgl.remove_edges(g, eids)\n",
    "    \n",
    "    pseudo_u = [e[0] for e in pseudo_edges] + [e[1] for e in pseudo_edges]\n",
    "    pseudo_v = [e[1] for e in pseudo_edges] + [e[0] for e in pseudo_edges]\n",
    "    g_test.add_edges(np.array(pseudo_u), np.array(pseudo_v))\n",
    "    print(g_test.number_of_edges())\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### debugging element ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node ids don't seem to match - probably the graph dataset was extracted from a different version of ifc file with different element ids\n",
    "# first, check ids in the merged file - compare with the ids from the param data\n",
    "# also check ids in the merged file with node dataset\n",
    "\n",
    "# import ifcopenshell\n",
    "# from ifcopenshell.util.selector import Selector\n",
    "\n",
    "# ifc = ifcopenshell.open(data_path +\"merged.ifc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ifc_tee = ifcopenshell.open(data_path +\"deckboxtee_ref.ifc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element_type = 'IFCPIPEFITTING'\n",
    "# #element_type = 'IFCPIPESEGMENT'\n",
    "# selector = Selector()\n",
    "# elements = selector.parse(ifc, '.' + element_type)\n",
    "# print(len(elements))\n",
    "# ids= []\n",
    "# for e in elements:\n",
    "#     ids.append(e.id())\n",
    "# print(len(ids), ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path + 'nodes_westdeckbox_ref.pkl', 'rb') as f:\n",
    "#     node_info = pickle.load(f)\n",
    "#     nodes = node_info[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_tee = [n[4] for n in nodes if n[0]==1]\n",
    "# #ids_tee = [n[4] for n in nodes]\n",
    "# print(len(ids_tee))\n",
    "# # node_ids = [n[4] for n in nodes if n[0]==3 or n[0]==4]\n",
    "# # print(len(node_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# elements_tee = selector.parse(ifc_tee, '.' + element_type)\n",
    "# print(len(elements_tee))\n",
    "# ids_tee= []\n",
    "# for e in elements_tee:\n",
    "#     ids_tee.append(e.id())\n",
    "# print(len(ids_tee), ids_tee[:10], max(ids_tee), max(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches, non_matches = [], []\n",
    "\n",
    "# for id1 in tqdm(ids_tee):\n",
    "#     found = False\n",
    "#     for i, id2 in enumerate(ids):\n",
    "#         if id1 == id2:\n",
    "#             matches.append((id1, i))\n",
    "#             found = True\n",
    "#             break\n",
    "#     if not found:\n",
    "#         non_matches.append(id1)\n",
    "               \n",
    "# print(len(matches), len(non_matches))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xq8E_7erObZs"
   },
   "source": [
    "Prepare training and testing sets\n",
    "---------------------------------\n",
    "\n",
    "This cell randomly picks 10% of the edges for positive examples in\n",
    "the test set, and leaves the rest for the training set. It then samples\n",
    "the same number of edges for negative examples in both sets.\n",
    "\n",
    "Ignore for evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RI6Beil3ObZt"
   },
   "outputs": [],
   "source": [
    "# Split edge set for training and testing\n",
    "if not test_mode:\n",
    "    u, v = g.edges()\n",
    "\n",
    "    eids = np.arange(g.number_of_edges())\n",
    "    eids = np.random.permutation(eids)\n",
    "    test_size = int(len(eids) * 0.1)\n",
    "    train_size = g.number_of_edges() - test_size\n",
    "    test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "    train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "\n",
    "    # Find all negative edges and split them for training and testing\n",
    "    #print(u.numpy().shape, v.numpy().shape)\n",
    "\n",
    "    adj = sp.coo_matrix((np.ones(len(u)), (u.cpu().numpy(), v.cpu().numpy())), \n",
    "                        shape=(g.number_of_nodes(), g.number_of_nodes()))\n",
    "    #print(adj.shape, adj.todense().shape, np.eye(g.number_of_nodes()).shape)\n",
    "    adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
    "    neg_u, neg_v = np.where(adj_neg != 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamically sample negative edges to create negative graph\n",
    "def construct_negative_graph(g, total_train_neg_eids, train_size):\n",
    "#     t1 = time.perf_counter()\n",
    "    train_neg_eids_eids = np.random.choice(len(total_train_neg_eids), train_size)\n",
    "    train_neg_eids = total_train_neg_eids[train_neg_eids_eids]\n",
    "    train_neg_u = neg_u[train_neg_eids] \n",
    "    train_neg_v = neg_v[train_neg_eids]\n",
    "    train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
    "    train_neg_g = train_neg_g.to(device)\n",
    "\n",
    "#     t2 = time.perf_counter()\n",
    "#     print(\"time\", t2-t1)\n",
    "#     print(train_neg_eids[:10])\n",
    "    return train_neg_g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a test set, and isolate all remaining negative edges for sampling later\n",
    "if not test_mode:\n",
    "    test_neg_eids = np.random.choice(len(neg_u), test_size*negative_sampling_ratio)\n",
    "    test_neg_eids = np.sort(test_neg_eids)\n",
    "    all_indices = np.arange(len(neg_u))\n",
    "    total_train_neg_eids = np.delete(all_indices, test_neg_eids)\n",
    "    print(len(test_neg_eids), len(total_train_neg_eids))\n",
    "\n",
    "#     total_train_neg_eids = []\n",
    "#     k = 0\n",
    "#     for i in tqdm(range(len(neg_u))):\n",
    "#         if k==len(test_neg_eids):\n",
    "#             total_train_neg_eids.append(i)\n",
    "#             continue\n",
    "#         if i != test_neg_eids[k]:\n",
    "#             total_train_neg_eids.append(i)\n",
    "#         else:\n",
    "#             k+=1\n",
    "#     print(len(test_neg_eids) + len(total_train_neg_eids) - len(neg_u))\n",
    "\n",
    "    test_neg_u, test_neg_v = neg_u[test_neg_eids], neg_v[test_neg_eids]\n",
    "    total_train_neg_eids = np.array(total_train_neg_eids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhcyOy04ObZu"
   },
   "outputs": [],
   "source": [
    "# remove edges of testset for training\n",
    "if not test_mode:\n",
    "    train_g = dgl.remove_edges(g, eids[:test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfqj5PUFObZw"
   },
   "outputs": [],
   "source": [
    "# construct the positive graph and the negative graph for the training set and the test set respectively.\n",
    "if not test_mode:\n",
    "    train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
    "    #train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
    "\n",
    "    test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
    "    test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())\n",
    "    test_pos_g = test_pos_g.to(device)\n",
    "    test_neg_g = test_neg_g.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxfARbi9ObZv"
   },
   "source": [
    "GraphSAGE model\n",
    "-------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_missing = False\n",
    "use_custom_feats = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extact radius, direction and position of edge from feature tensor\n",
    "def get_rdp_tensor(feat, e, feat_size):\n",
    "    r = feat[:, feat_size+1+e]\n",
    "    p = torch.column_stack([feat[:, feat_size+4+e*3], \n",
    "                            feat[:, feat_size+5+e*3], \n",
    "                            feat[:, feat_size+6+e*3]])\n",
    "    d = torch.column_stack([feat[:, feat_size+13+e*3], \n",
    "                            feat[:, feat_size+14+e*3], \n",
    "                            feat[:, feat_size+15+e*3]])\n",
    "    return r, d, p\n",
    "\n",
    "\n",
    "# get angle deviation between two pipe centerlines\n",
    "def get_centerline_deviation_tensor(d1, d2):\n",
    "    dev = torch.acos( torch.sum(d1*d2, dim=-1))\n",
    "    dev = torch.where(dev > np.pi/2, np.pi - dev, dev)\n",
    "    return dev\n",
    "\n",
    "\n",
    "# get euclidean distance between two points\n",
    "def get_point_dist_tensor(p1, p2):\n",
    "    return(torch.sqrt(torch.sum((p1-p2).pow(2), -1)))\n",
    "\n",
    "\n",
    "# replace edge features with zeros where radius is zero\n",
    "def replace_for_zero_r_tensor(inp, src_r, tgt_r):\n",
    "    return torch.where(torch.logical_or(src_r == 0, tgt_r == 0),\n",
    "                       torch.zeros(inp.shape).to(device),\n",
    "                       inp)\n",
    "\n",
    "\n",
    "#TODO: intergrate dist to intersection as edge feature\n",
    "def get_distance_to_intersection_tensor(p1, p2, d1, d2):\n",
    "    centerline_connecting_line = F.normalize(torch.cross(d1, d2))\n",
    "    center_connecting_line = p2 - p1\n",
    "    centerline_distance = (torch.abs(torch.sum(centerline_connecting_line*center_connecting_line, \n",
    "                                               dim=-1)) / \n",
    "                           torch.linalg.vector_norm(centerline_connecting_line, dim=1))\n",
    "    sq_mag_ccl = torch.sum(centerline_connecting_line*centerline_connecting_line,\n",
    "                           dim=-1)\n",
    "    t1 = torch.sum(torch.cross(d2, centerline_connecting_line)*center_connecting_line, \n",
    "                   dim=-1) / sq_mag_ccl\n",
    "    t2 = torch.sum(torch.cross(d1, centerline_connecting_line)*center_connecting_line, \n",
    "                   dim=-1) / sq_mag_ccl\n",
    "    \n",
    "    #print(t1.shape, t2.shape)\n",
    "    return t1, t2\n",
    "\n",
    "\n",
    "def get_distance_to_intersection(a, b):\n",
    "    centerline_connecting_line = np.cross(a[3], b[3])\n",
    "    center_connecting_line = b[1] - a[1]\n",
    "    centerline_distance = (abs(np.dot(centerline_connecting_line, \n",
    "                                          center_connecting_line)) / \n",
    "                           vector_mag(centerline_connecting_line))\n",
    "    sq_mag_ccl = np.dot(centerline_connecting_line, \n",
    "                        centerline_connecting_line)\n",
    "    t1 = np.dot(np.cross(b[3], centerline_connecting_line),\n",
    "                center_connecting_line) / sq_mag_ccl\n",
    "    t2 = np.dot(np.cross(a[3], centerline_connecting_line),\n",
    "                center_connecting_line) / sq_mag_ccl\n",
    "    \n",
    "    return t1, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate custom edge features\n",
    "def get_edge_features(src_nodes, tgt_nodes):\n",
    "    feature_columns = []\n",
    "\n",
    "    # iterate through edges of first element\n",
    "    for e1 in range(3):\n",
    "        src_r, src_d, src_p = get_rdp_tensor(src_nodes, e1, 0)\n",
    "        \n",
    "        # iterate through edges of second element\n",
    "        for e2 in range(3):\n",
    "            tgt_r, tgt_d, tgt_p = get_rdp_tensor(tgt_nodes, e2, 0)\n",
    "\n",
    "            # compute edge features\n",
    "            r_ratio = src_r / tgt_r\n",
    "            deviation = get_centerline_deviation_tensor(src_d, tgt_d)\n",
    "            point_dist = get_point_dist_tensor(src_p, tgt_p)\n",
    "            t1, t2 = get_distance_to_intersection_tensor(src_p, tgt_p, src_d, tgt_d)\n",
    "\n",
    "            # remove edge features when one edge has zero radius\n",
    "            r_ratio = replace_for_zero_r_tensor(r_ratio, src_r, tgt_r)\n",
    "            deviation = replace_for_zero_r_tensor(deviation, src_r, tgt_r)\n",
    "            point_dist = replace_for_zero_r_tensor(point_dist, src_r, tgt_r)\n",
    "            t1 = replace_for_zero_r_tensor(t1, src_r, tgt_r)\n",
    "            t2 = replace_for_zero_r_tensor(t2, src_r, tgt_r)\n",
    "\n",
    "            feature_columns.append(r_ratio)\n",
    "            feature_columns.append(deviation)\n",
    "            feature_columns.append(point_dist)\n",
    "            #feature_columns.append(t1)\n",
    "            #feature_columns.append(t2)\n",
    "            \n",
    "            \n",
    "    feature_columns.append(src_nodes[:, 0])\n",
    "    feature_columns.append(tgt_nodes[:, 0])\n",
    "            \n",
    "\n",
    "    feature_columns_tensor = torch.column_stack(feature_columns)\n",
    "    #print(feature_columns_tensor.shape)\n",
    "    return feature_columns_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07x2B1_RObZv"
   },
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a 3-layer GraphSAGE model\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "        self.conv3 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "#         self.conv4 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "#         self.conv5 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "#         self.conv6 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "#         self.conv7 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "#         self.conv8 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "    \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv3(g, h)\n",
    "#         h = F.relu(h)\n",
    "#         h = self.conv4(g, h)\n",
    "#         h = F.relu(h)\n",
    "#         h = self.conv5(g, h)\n",
    "#         h = F.relu(h)\n",
    "#         h = self.conv6(g, h)\n",
    "#         h = F.relu(h)\n",
    "#         h = self.conv7(g, h)\n",
    "#         h = F.relu(h)\n",
    "#         h = self.conv8(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mk5OgXZZObZx"
   },
   "outputs": [],
   "source": [
    "# compute edge features using dot product\n",
    "\n",
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # Compute a new edge feature named 'score' by a dot-product between the\n",
    "            # source node feature 'h' and destination node feature 'h'.\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
    "            return g.edata['score'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frksQEAnObZx"
   },
   "outputs": [],
   "source": [
    "# ALTERNATIVE: compute edge features using an MLP\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.h_feats = h_feats\n",
    "        custom_feats = 0\n",
    "        if use_custom_feats:\n",
    "            custom_feats = 29\n",
    "\n",
    "#         self.W1 = nn.Linear(h_feats * 2+ custom_feats, h_feats)\n",
    "#         self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "#         self.W1 = nn.Linear(h_feats * 2 + custom_feats, h_feats)\n",
    "#         self.W2 = nn.Linear(h_feats, int(h_feats/2))\n",
    "#         self.W3 = nn.Linear(int(h_feats/2), 1)\n",
    "\n",
    "#         self.W1 = nn.Linear(h_feats * 2 + custom_feats, h_feats)\n",
    "#         self.W2 = nn.Linear(h_feats, int(h_feats/2))\n",
    "#         self.W3 = nn.Linear(int(h_feats/2), 4)\n",
    "#         self.W4 = nn.Linear(4, 1)\n",
    "\n",
    "        self.W1 = nn.Linear(h_feats * 2 + custom_feats, h_feats*2)\n",
    "        self.W2 = nn.Linear(h_feats*2, h_feats)\n",
    "        self.W3 = nn.Linear(h_feats, int(h_feats/2))\n",
    "        self.W4 = nn.Linear(int(h_feats/2), 4)\n",
    "        self.W5 = nn.Linear(4, 1)\n",
    "        \n",
    "#         self.W1 = nn.Linear(h_feats * 2 + custom_feats, h_feats*4)\n",
    "#         self.W2 = nn.Linear(h_feats*4, h_feats*2)\n",
    "#         self.W3 = nn.Linear(h_feats*2, h_feats)\n",
    "#         self.W4 = nn.Linear(4, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        \"\"\"\n",
    "        Computes a scalar score for each edge of the given graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        edges :\n",
    "            Has three members ``src``, ``dst`` and ``data``, each of\n",
    "            which is a dictionary representing the features of the\n",
    "            source nodes, the destination nodes, and the edges\n",
    "            themselves.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of new edge features.\n",
    "        \"\"\"\n",
    "        \n",
    "        # compute custom edge features\n",
    "        if use_custom_feats:\n",
    "            edge_features = get_edge_features(edges.src['h'][:,self.h_feats:], \n",
    "                                              edges.dst['h'][:,self.h_feats:])\n",
    "\n",
    "            h = torch.cat([edges.src['h'][:,:self.h_feats], \n",
    "                           edges.dst['h'][:,:self.h_feats], \n",
    "                           edge_features], \n",
    "                      1)\n",
    "        else:\n",
    "            h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "            \n",
    "        #print(\"in\", edges.src['h'].shape, \"edge\", edge_features.shape, \"out\", h.shape)\n",
    "\n",
    "        #return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "        #return {'score': self.W3(F.relu(self.W2(F.relu(self.W1(h))))).squeeze(1)}\n",
    "        #return {'score': self.W4(F.relu(self.W3(F.relu(self.W2(F.relu(self.W1(h))))))).squeeze(1)}\n",
    "        return {'score': self.W5(F.relu(self.W4(F.relu(self.W3(F.relu(self.W2(F.relu(self.W1(h))))))))).squeeze(1)}\n",
    "\n",
    "        #return {'score': self.W1(h).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytKvY1PPObZy"
   },
   "source": [
    "Training setup\n",
    "-------------\n",
    "\n",
    "\n",
    "\n",
    "The loss function is binary cross entropy loss.\n",
    "\n",
    "\\begin{align}\\mathcal{L} = -\\sum_{u\\sim v\\in \\mathcal{D}}\\left( y_{u\\sim v}\\log(\\hat{y}_{u\\sim v}) + (1-y_{u\\sim v})\\log(1-\\hat{y}_{u\\sim v})) \\right)\\end{align}\n",
    "\n",
    "The evaluation metric  is AUC.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g.ndata['feat'].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TELwQMhoObZy"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "feat_size = 16\n",
    "custom_edge_feature_size = 22\n",
    "\n",
    "if test_mode:\n",
    "  model = GraphSAGE(g.ndata['feat'].shape[1], feat_size)\n",
    "else:\n",
    "  model = GraphSAGE(train_g.ndata['feat'].shape[1], feat_size)\n",
    "\n",
    "model = model.to(torch.double)\n",
    "model = model.to(device)\n",
    "\n",
    "# You can replace DotPredictor with MLPPredictor.\n",
    "pred = MLPPredictor(feat_size)\n",
    "# pred = DotPredictor()\n",
    "pred = pred.to(torch.double)\n",
    "pred = pred.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    #print(scores)\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]).to(device), \n",
    "                        torch.zeros(neg_score.shape[0]).to(device)])\n",
    "    #w = torch.as_tensor([0.01 for i in range(len(labels))])\n",
    "    #return F.binary_cross_entropy_with_logits(scores, labels, w)\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQb634YtQHfU"
   },
   "outputs": [],
   "source": [
    "from numpy.lib.function_base import average\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(pos_score, neg_score, threshold=0.8):\n",
    "    # for x in torch.cat([pos_score, neg_score]):\n",
    "    #   print(x)\n",
    "\n",
    "    scores = torch.sigmoid(torch.cat([pos_score, neg_score])).cpu().numpy()\n",
    "    #scores = np.rint(scores).astype(int)\n",
    "    scores[scores > threshold] = 1\n",
    "    scores[scores != 1] = 0\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    #print(np.average(scores), scores.shape, labels.shape)\n",
    "    return (accuracy_score(labels, scores), precision_score(labels, scores), \n",
    "            recall_score(labels, scores), f1_score(labels, scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_with_mean(feat):\n",
    "    #print(feat[:20])\n",
    "    r_key = 3\n",
    "    fields = [10, 11, 12, 19, 20, 21, 3]\n",
    "    for f in fields:\n",
    "        #print(torch.count_nonzero(feat[:,r_key]))\n",
    "        mean = torch.sum(feat[:,f]) / torch.count_nonzero(feat[:,r_key])\n",
    "        mean_tensor = torch.full(feat[:,f].shape, mean).to(device)\n",
    "        #print(mean, mean_tensor.shape)\n",
    "        feat_copy = torch.clone(feat)\n",
    "        feat_copy[:,f] = torch.where(feat_copy[:,r_key] == 0, mean_tensor, feat_copy[:,f])\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if impute_missing:\n",
    "    if test_mode:\n",
    "        imputed_feat_g = impute_missing_with_mean(g.ndata['feat'])\n",
    "    else:\n",
    "        imputed_feat = impute_missing_with_mean(train_g.ndata['feat'])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "load pre-trained model and run on entire dataset in batches (due to the large size of negative dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmXVcu8u96yN"
   },
   "outputs": [],
   "source": [
    "if test_mode:\n",
    "\n",
    "    # load model\n",
    "    model.load_state_dict(torch.load(model_path + model_name))\n",
    "    pred.load_state_dict(torch.load(model_path + pred_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YkrHm4V6Eoni"
   },
   "outputs": [],
   "source": [
    "# validation set\n",
    "if test_mode:\n",
    "  u, v = g.edges()\n",
    "  eids = np.arange(g.number_of_edges())\n",
    "  \n",
    "  adj = sp.coo_matrix((np.ones(len(u)), (u.cpu().numpy(), v.cpu().numpy())), \n",
    "                      shape=(g.number_of_nodes(), g.number_of_nodes()))\n",
    "  adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
    "  neg_u_full, neg_v_full = np.where(adj_neg != 0)\n",
    "  print(len(neg_u_full))\n",
    "  #neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_mode:    \n",
    "    with open(model_path + 'eval/pos_edges_test.pkl', 'wb') as f:\n",
    "                pickle.dump([u,v], f)\n",
    "    with open(model_path + 'eval/neg_edges_test.pkl', 'wb') as f:\n",
    "                pickle.dump([neg_u_full,neg_v_full], f)\n",
    "    print(len(u), len(neg_u_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hSAxeePMgPk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if test_mode:\n",
    "    with torch.no_grad():\n",
    "       \n",
    "        if impute_missing:\n",
    "            h = model(g_test, imputed_feat_g)\n",
    "        else:\n",
    "            h = model(g_test, g.ndata['feat'])\n",
    "\n",
    "        if use_custom_feats:\n",
    "            h = torch.cat([h, g.ndata['feat'][:,:custom_edge_feature_size]], 1)\n",
    "        \n",
    "        # evaluate positive examples\n",
    "        val_pos_g = dgl.graph((u, v), num_nodes=g.number_of_nodes())\n",
    "        pos_score = pred(val_pos_g, h).cpu().numpy()\n",
    "        \n",
    "        with open(model_path + '/eval/pos_score_test.pkl', 'wb') as f:\n",
    "            pickle.dump(pos_score, f)\n",
    "\n",
    "        # evaluate negative examples\n",
    "        sample_size = 2000000\n",
    "        limit = math.ceil(len(neg_u_full)/sample_size)\n",
    "        #print(len(neg_u_full), limit)\n",
    "        neg_scores = []\n",
    "        \n",
    "        for i in tqdm(range(limit)):\n",
    "            if i == limit-1:\n",
    "                neg_u, neg_v = neg_u_full[i*sample_size:], neg_v_full[i*sample_size:]\n",
    "            else:\n",
    "                neg_u = neg_u_full[i*sample_size:(i+1)*sample_size]\n",
    "                neg_v = neg_v_full[i*sample_size:(i+1)*sample_size]\n",
    "            #print(i, len(neg_u), neg_u[0],  neg_v[0])\n",
    "\n",
    "            val_neg_g = dgl.graph((neg_u, neg_v), num_nodes=g.number_of_nodes())\n",
    "            val_neg_g = val_neg_g.to(device)\n",
    "            neg_scores.append(pred(val_neg_g, h).cpu().numpy())\n",
    "        \n",
    "        neg_score = np.concatenate(neg_scores)\n",
    "        with open(model_path + '/eval/neg_score_test.pkl', 'wb') as f:\n",
    "            pickle.dump(neg_score, f)\n",
    "#             print('AUC', compute_auc(pos_score, neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_mode:\n",
    "\n",
    "    with open(model_path + '/eval/pos_score_test.pkl', 'rb') as f:\n",
    "        pos_score = pickle.load(f)\n",
    "\n",
    "    with open(model_path + '/eval/neg_score_test.pkl', 'rb') as f:\n",
    "        neg_score = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_mode:\n",
    "    print(len(pos_score), len(neg_score), sum(pos_score)/len(pos_score), sum(neg_score)/len(neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if test_mode:\n",
    "    metrics = compute_metrics(torch.from_numpy(pos_score), torch.from_numpy(neg_score))\n",
    "    print('accuracy', metrics[0])\n",
    "    print('precision', metrics[1])\n",
    "    print('recall', metrics[2])\n",
    "    print('f1_score', metrics[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train / validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qiVgzAd7ObZy",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----------- 3. set up loss and optimizer -------------- #\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.001)\n",
    "\n",
    "# ----------- 4. training -------------------------------- #\n",
    "all_logits = []\n",
    "accuracies = []\n",
    "losses = []\n",
    "\n",
    "\n",
    "for e in tqdm(range(1500)):\n",
    "    # forward\n",
    "    #print(len(c))\n",
    "    train_neg_g = construct_negative_graph(g, total_train_neg_eids, train_size*negative_sampling_ratio)\n",
    "    #print(train_g.ndata['feat'].device, train_g.device)\n",
    "    if impute_missing:\n",
    "        h = model(train_g, imputed_feat)\n",
    "    else:\n",
    "        h = model(train_g, train_g.ndata['feat'])\n",
    "    \n",
    "    # concatanate original node features for custom edge feature computation\n",
    "    if use_custom_feats:\n",
    "        h = torch.cat([h, train_g.ndata['feat'][:,:custom_edge_feature_size]], 1)\n",
    "\n",
    "    pos_score = pred(train_pos_g, h)\n",
    "    neg_score = pred(train_neg_g, h)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "    \n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    highest_f1 = 0\n",
    "    \n",
    "    if e % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "          pos_score_test = pred(test_pos_g, h)\n",
    "          neg_score_test = pred(test_neg_g, h)\n",
    "          auc =  compute_auc(pos_score_test, neg_score_test)\n",
    "          metrics = compute_metrics(pos_score_test, neg_score_test)\n",
    "          test_loss = compute_loss(pos_score_test, neg_score_test)\n",
    "          res_sring = 'epoch {}, training loss: {:.3f}, test loss: {:.3f}, auc: {:.3f}, f1: {:.3f}, pr: {:.3f}, re{:.3f}'\n",
    "          print(res_sring.format(e, loss, test_loss, auc, float(metrics[3]), \n",
    "                                 float(metrics[1]), float(metrics[2])))\n",
    "        \n",
    "          if metrics[3] > highest_f1:\n",
    "            torch.save(model.state_dict(), model_path + model_name)\n",
    "            torch.save(pred.state_dict(), model_path + pred_name)\n",
    "          # metrics = compute_metrics(pos_score, neg_score)\n",
    "          accuracies.append(auc)\n",
    "          losses.append(loss.item())\n",
    "\n",
    "\n",
    "# ----------- 5. check results ------------------------ #\n",
    "print(\"max AUC\", max(accuracies))\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g, h)\n",
    "    neg_score = pred(test_neg_g, h)\n",
    "    print('AUC', compute_auc(pos_score, neg_score))\n",
    "    \n",
    "# for i in range(len(losses)):\n",
    "#     print(i*5, losses[i], accuracies[i])\n",
    "#     print('AUC', compute_auc(pos_score, neg_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_path + model_name))\n",
    "pred.load_state_dict(torch.load(model_path + pred_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XEs4t_LtHHb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    #h = model(train_g, train_g.ndata['feat'])\n",
    "    pos_score = pred(test_pos_g, h)\n",
    "    neg_score = pred(test_neg_g, h)\n",
    "    metrics = compute_metrics(pos_score, neg_score)\n",
    "    print('accuracy', metrics[0])\n",
    "    print('precision', metrics[1])\n",
    "    print('recall', metrics[2])\n",
    "    print('f1_score', metrics[3])\n",
    "    print('auc', compute_auc(pos_score, neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_pos_u), len(test_neg_u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate separate metrics based on element classes\n",
    "# print(g.ndata[\"feat\"][test_pos_u[0]])\n",
    "# print(np.unique(g.ndata[\"feat\"].numpy()[:,0]))\n",
    "\n",
    "type_pairs = [(0., 0.), (0., 1.), (0., 2.), (0., 3.), (0., 4.), \n",
    "              (1., 1.), (1., 2.), (1., 3.), (1., 4.), (2., 2.), \n",
    "              (2., 3.), (2., 4.), (3., 3.), (3., 4.), (4., 4.)]\n",
    "\n",
    "def split_graph(u, v, node_features, type_pairs):\n",
    "    subgraph_edges = {pair: ([], []) for pair in type_pairs}\n",
    "    subgraphs = {}\n",
    "    \n",
    "    for i in range(len(u)):\n",
    "        u_type = node_features[u[i], 0]\n",
    "        v_type = node_features[v[i], 0]\n",
    "        \n",
    "        edge_type = (u_type, v_type)\n",
    "        if edge_type in subgraph_edges:\n",
    "            subgraph_edges[edge_type][0].append(u[i])\n",
    "            subgraph_edges[edge_type][1].append(v[i])\n",
    "\n",
    "    \n",
    "    for pair, (sub_u, sub_v) in subgraph_edges.items():\n",
    "        pos_g = dgl.graph((sub_u, sub_v), num_nodes=g.number_of_nodes())\n",
    "        #test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())\n",
    "        subgraphs[pair] = pos_g.to(device)\n",
    "        \n",
    "    return subgraphs\n",
    "\n",
    "pos_subgraphs = split_graph(test_pos_u, test_pos_v, g.ndata[\"feat\"].cpu().numpy(), type_pairs)\n",
    "neg_subgraphs = split_graph(test_neg_u, test_neg_v, g.ndata[\"feat\"].cpu().numpy(), type_pairs)\n",
    "#print(neg_subgraphs)\n",
    "\n",
    "\n",
    "for pair, pos_sub_g in pos_subgraphs.items():\n",
    "    print((types[int(pair[0])], types[int(pair[1])]))\n",
    "    print(\"positive edges\", pos_sub_g.num_edges())\n",
    "    print(\"negative edges\", neg_subgraphs[pair].num_edges())\n",
    "#     print(f\"Subgraph for type pair {pair}:\")\n",
    "#     print(f\"u: {sub_u}\")\n",
    "#     print(f\"v: {sub_v}\\n\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pos_score = pred(pos_sub_g, h)\n",
    "        neg_score = pred(neg_subgraphs[pair], h)\n",
    "        try:\n",
    "            metrics = compute_metrics(pos_score, neg_score)\n",
    "            print('accuracy', metrics[0])\n",
    "            print('precision', metrics[1])\n",
    "            print('recall', metrics[2])\n",
    "            print('f1_score', metrics[3])\n",
    "            print('auc', compute_auc(pos_score, neg_score))\n",
    "        except:\n",
    "            print(\"metric error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1jeKlDB_K_n"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), model_path + model_name)\n",
    "torch.save(pred.state_dict(), model_path + pred_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4_link_predict.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

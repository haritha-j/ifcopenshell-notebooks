{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpvL68OfBEQC"
   },
   "source": [
    "# Element Parameter Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-z7n_pw4SMWl"
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJ47VNF7fmTS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import os.path\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from ipywidgets import interact \n",
    "import gc\n",
    "import open3d as o3d\n",
    "\n",
    "from src.elements import *\n",
    "from src.ifc import *\n",
    "from src.preparation import *\n",
    "from src.visualisation import *\n",
    "from src.chamfer import *\n",
    "from src.utils import *s\n",
    "from src.morph import *\n",
    "\n",
    "random.seed = 42\n",
    "rng = default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sphere morphing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise a list of point clouds as an animation using open3d\n",
    "# use ctrl+c to copy and ctrl+v to set camera and zoom inside visualiser\n",
    "def create_point_cloud_animation(cloud_list, loss_func, save_image=False, colours=None):\n",
    "    o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Debug)\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    cloud = cloud_list[0]\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(cloud)\n",
    "    if colours is not None:\n",
    "        point_cloud.colors = o3d.utility.Vector3dVector(colours[0])\n",
    "    vis.add_geometry(point_cloud)\n",
    "    stops = [9,39,99,299,999]\n",
    "\n",
    "    for i in range(len(cloud_list)):\n",
    "        time.sleep(0.01 + 0.05/(i/10+1))\n",
    "        cloud = cloud_list[i]\n",
    "        point_cloud.points = o3d.utility.Vector3dVector(cloud)\n",
    "        if colours is not None:\n",
    "            point_cloud.colors = o3d.utility.Vector3dVector(colours[i])\n",
    "        vis.update_geometry(point_cloud)\n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "        if save_image and i in stops:\n",
    "            vis.capture_screen_image(\"sphere/\" + loss_func + str(i) + \".jpg\", do_render=True)\n",
    "    vis.destroy_window()\n",
    "\n",
    "    o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cld1_name = \"sphere/chair.pcd\"\n",
    "# loss_func = \"chamfer\"\n",
    "# run_morph(cld1_name, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "# visualise animation\n",
    "cld1_name = \"sphere/plane1.pcd\"\n",
    "visualise = True\n",
    "#loss_funcs = [ \"chamfer\", \"emd\", \"balanced\", \"reverse\", \"single\"]\n",
    "#loss_funcs = [ \"balanced\", \"single\"]\n",
    "loss_funcs = [ \"density\"]\n",
    "for loss_func in loss_funcs:\n",
    "    print(loss_func)\n",
    "    run_morph(cld1_name, loss_func)\n",
    "    if visualise:\n",
    "        with open(\"sphere/\" + loss_func + \".pkl\", \"rb\") as f:\n",
    "            morphed = pickle.load(f)\n",
    "        colours = visualise_density(morphed, 'plasma_r')\n",
    "        with open(\"sphere/\" + loss_func + \"_dens.pkl\", \"wb\") as f:\n",
    "            pickle.dump(colours, f)\n",
    "        #create_point_cloud_animation(cloud_list, loss_func)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def view_density(loss_func): \n",
    "    with open(\"sphere/\" + loss_func + \".pkl\", \"rb\") as f:\n",
    "        morphed = pickle.load(f)\n",
    "    with open(\"sphere/\" + loss_func + \"_dens.pkl\", \"rb\") as f:\n",
    "        colours = pickle.load(f)\n",
    "\n",
    "    create_point_cloud_animation(morphed, loss_func, True, colours[:,:,:3])\n",
    "    \n",
    "interact(view_density, loss_func=[ \"density\", \"balanced\", \"infocd\", \"single\", \"chamfer\", \"reverse\", \"emd\", \"direct\"]); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# visualise animation\n",
    "loss_func = \"emd\"\n",
    "with open(\"sphere/\" + loss_func + \".pkl\", \"rb\") as f:\n",
    "    morphed = pickle.load(f)\n",
    "print(morphed.shape, loss_func)\n",
    "cloud_list = [m for m in morphed]\n",
    "#create_point_cloud_animation(cloud_list, loss_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = visualise_density(morphed, 'plasma_r')\n",
    "with open(\"sphere/\" + loss_func + \"_dens.pkl\", \"wb\") as f:\n",
    "    pickle.dump(colours, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch optimisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample\n",
    "shapenet_path = \"../experiments/ICCV2023-HyperCD/ShapeNetCompletion/test/complete/\"\n",
    "downsampled_path = \"../experiments/ICCV2023-HyperCD/ShapeNetCompletion/downsample/\"\n",
    "# folders = os.listdir(shapenet_path)\n",
    "# choices = np.random.choice(len(points), 4096)\n",
    "\n",
    "# for fl in tqdm(folders):\n",
    "#     if not os.path.exists(downsampled_path+fl):\n",
    "#         os.mkdir(downsampled_path+fl)\n",
    "        \n",
    "#     files = os.listdir(shapenet_path + fl)\n",
    "#     cloud =  o3d.geometry.PointCloud()\n",
    "#     for cl in files:\n",
    "#         points = np.array(o3d.io.read_point_cloud(shapenet_path + fl + \"/\" + cl).points)\n",
    "#         points = points[choices]\n",
    "#         cloud.points = o3d.utility.Vector3dVector(points)\n",
    "#         o3d.io.write_point_cloud(downsampled_path+fl + \"/\" + cl, cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = \"balanced\"\n",
    "#loss_func = \"emd\"\n",
    "\n",
    "sphere_morph_metrics(loss_func, downsampled_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses on same axis\n",
    "def plot_losses(losses, labels, title):\n",
    "    x = np.arange(0, len(losses[0]))\n",
    "    plt.figure(figsize=(30, 6))\n",
    "    for i, loss in enumerate(losses):\n",
    "        plt.plot(x, loss, label=labels[i])\n",
    "\n",
    "    plt.xlabel(\"point cloud index\")\n",
    "    plt.ylabel(\"distance\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plots\n",
    "loss_funcs = [\"chamfer\"]\n",
    "chamfer_list, emd_list = [], []\n",
    "for loss_func in loss_funcs:\n",
    "    with open(\"sphere/\" + loss_func + \"_metrics.pkl\", \"rb\") as f:\n",
    "        chamfer, emd, assignments = pickle.load(f)\n",
    "        chamfer_list.append(chamfer)\n",
    "        emd_list.append(emd)\n",
    "        \n",
    "plot_losses(chamfer_list, loss_funcs, \"chamfer\")\n",
    "\n",
    "ts(emd_list, loss_funcs, \"EMD\")\n",
    "        \n",
    "print(emd_list[-1], chamfer_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load losses\n",
    "loss_types = [\"reverse\", \"chamfer\", \"emd\", \"pair\"]\n",
    "losses = []\n",
    "\n",
    "for loss_func in loss_types:\n",
    "    with open(\"sphere/loss_\" + loss_func + \".pkl\", \"rb\") as f:\n",
    "        losses.append(pickle.load(f))\n",
    "        \n",
    "plot_losses(losses, loss_types, \"loss function comparison\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### consistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure conssistency between forward and backward correspondences for chamfer distance\n",
    "# optionally compare against the ideal assignment, as measured by EMD\n",
    "def measure_assignment_consistency(assignment, emd=None):\n",
    "    reverse_assignment = torch.gather(assignment[0], 0, assignment[1])\n",
    "    expected = torch.arange(assignment[0].shape[0], device=torch.device(\"cuda\"))\n",
    "    consistency = torch.sum(torch.eq(expected, reverse_assignment).long())\n",
    "    print(\"consistency\", consistency.item(), len(torch.unique(assignment[0])), len(torch.unique(assignment[1])))\n",
    "    \n",
    "    if emd is not None:\n",
    "        #print(emd[:5], assignment[0][:5], assignment[1][:5])\n",
    "        emd_consistency = torch.sum(torch.eq(emd, assignment[0]).long())\n",
    "        #print(\"emd_consistency\", emd_consistency.item(), len(torch.unique(emd)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare correspondences\n",
    "#TODO: include consistency in top5 matches?\n",
    "loss_func = \"emd\"\n",
    "with open(\"sphere/assignments_\" + \"emd\" + \".pkl\", \"rb\") as f:\n",
    "    emd_assignment = pickle.load(f)\n",
    "\n",
    "with open(\"sphere/assignments_\" + loss_func + \".pkl\", \"rb\") as f:\n",
    "    assignment = pickle.load(f)\n",
    "    \n",
    "for i, ass in enumerate(assignment):\n",
    "    #measure_assignment_consistency(ass, emd_assignment[i][0])\n",
    "    measure_assignment_consistency(ass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

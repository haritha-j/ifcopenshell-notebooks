{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpvL68OfBEQC"
   },
   "source": [
    "# PointNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbPm1WS7UWe6"
   },
   "source": [
    "This is an implementation of [PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593) using PyTorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-z7n_pw4SMWl"
   },
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGjwJhn0VTVu"
   },
   "source": [
    "Don't forget to turn on GPU if you want to start training directly. \n",
    "\n",
    "\n",
    "**Runtime** -> **Change runtime type**-> **Hardware accelerator**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJ47VNF7fmTS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import scipy.spatial.distance\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import ifcopenshell\n",
    "from utils.JupyterIFCRenderer import JupyterIFCRenderer\n",
    "from path import Path\n",
    "import open3d as o3d\n",
    "\n",
    "from src.elements import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zncVRbuwtV2N",
    "outputId": "1f4230a2-eb21-4b06-e839-81ea9da114a3"
   },
   "outputs": [],
   "source": [
    "# !pip install path.py;\n",
    "# from path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OK01OV_bfmhv",
    "outputId": "f3a7b45e-3281-451d-f895-18c8efd86a19"
   },
   "outputs": [],
   "source": [
    "# !pip install open3d\n",
    "# import open3d as o3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpzTlKjmlr2q"
   },
   "outputs": [],
   "source": [
    "random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Qd_CpZ8ZbNC",
    "outputId": "ebbf1b32-042d-4fed-fb0e-e1d06d2d4308"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vg6HhI7eU80o"
   },
   "source": [
    "Download the [dataset](http://3dvision.princeton.edu/projects/2014/3DShapeNets/) directly to the Google Colab Runtime. It comprises 10 categories, 3,991 models for training and 908 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xyu78RWIQEQJ"
   },
   "outputs": [],
   "source": [
    "#path = Path(\"ModelNet10\")\n",
    "#path = Path('/content/drive/MyDrive/ElementNet/')\n",
    "path = Path('output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lp3uFKomP8AU"
   },
   "outputs": [],
   "source": [
    "#savepath = '/content/drive/MyDrive/ElementNet/'\n",
    "savepath = 'models/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2i_0ECIcR1X",
    "outputId": "b2a5cce5-f5e0-4262-f4b8-d22eacb1e9e8"
   },
   "outputs": [],
   "source": [
    "folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n",
    "classes = {folder: i for i, folder in enumerate(folders)};\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krbtoQtTXOBa"
   },
   "source": [
    "This dataset consists ofÂ **.off** files that contain meshes represented by *vertices* and *triangular faces*. \n",
    "\n",
    "We will need a function to read this type of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXEzgwr_Mfc0"
   },
   "outputs": [],
   "source": [
    "# def read_off(file):\n",
    "#     if 'OFF' != file.readline().strip():\n",
    "#         raise('Not a valid OFF header')\n",
    "#     n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
    "#     verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
    "#     faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
    "#     return verts, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nw_P2E17fD6c"
   },
   "outputs": [],
   "source": [
    "def read_pcd(file):\n",
    "    pcd = o3d.io.read_point_cloud(str(file))\n",
    "    return np.asarray(pcd.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddne6NHcPIHn"
   },
   "outputs": [],
   "source": [
    "f = path/\"elbow/test/19024.pcd\"\n",
    "pointcloud = read_pcd(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Le4-KXs1j1E3",
    "outputId": "9a76b0dd-cc25-4535-99bd-74a0e5a27a6d"
   },
   "outputs": [],
   "source": [
    "len(pointcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2XqwjkJXqLE"
   },
   "source": [
    "Don't be afraid of this huge function. It's  just to display animated rotation of meshes and point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dbIQBLykGpX"
   },
   "outputs": [],
   "source": [
    "def visualize_rotate(data):\n",
    "    x_eye, y_eye, z_eye = 1.25, 1.25, 0.8\n",
    "    frames=[]\n",
    "\n",
    "    def rotate_z(x, y, z, theta):\n",
    "        w = x+1j*y\n",
    "        return np.real(np.exp(1j*theta)*w), np.imag(np.exp(1j*theta)*w), z\n",
    "\n",
    "    for t in np.arange(0, 10.26, 0.1):\n",
    "        xe, ye, ze = rotate_z(x_eye, y_eye, z_eye, -t)\n",
    "        frames.append(dict(layout=dict(scene=dict(camera=dict(eye=dict(x=xe, y=ye, z=ze))))))\n",
    "    fig = go.Figure(data=data,\n",
    "                    layout=go.Layout(\n",
    "                        updatemenus=[dict(type='buttons',\n",
    "                                    showactive=False,\n",
    "                                    y=1,\n",
    "                                    x=0.8,\n",
    "                                    xanchor='left',\n",
    "                                    yanchor='bottom',\n",
    "                                    pad=dict(t=45, r=10),\n",
    "                                    buttons=[dict(label='Play',\n",
    "                                                    method='animate',\n",
    "                                                    args=[None, dict(frame=dict(duration=50, redraw=True),\n",
    "                                                                    transition=dict(duration=0),\n",
    "                                                                    fromcurrent=True,\n",
    "                                                                    mode='immediate'\n",
    "                                                                    )]\n",
    "                                                    )\n",
    "                                            ]\n",
    "                                    )\n",
    "                                ]\n",
    "                    ),\n",
    "                    frames=frames\n",
    "            )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0huQ5maYxBa9"
   },
   "outputs": [],
   "source": [
    "#visualize_rotate([go.Mesh3d(x=x, y=y, z=z, color='lightpink', opacity=0.50, i=i,j=j,k=k)]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fpGrWndRVYw"
   },
   "source": [
    "This mesh definitely looks like a bed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9hL_IOoMVzP"
   },
   "outputs": [],
   "source": [
    "# visualize_rotate([go.Scatter3d(x=x, y=y, z=z,\n",
    "#                                    mode='markers')]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ah0LVBEBRaGS"
   },
   "source": [
    "Unfortunately, that's not the case for its vertices. It would be difficult for PointNet to classify point clouds like this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBNJ__37RBvi"
   },
   "source": [
    "First things first, let's write a function to accurately visualize point clouds so we could see vertices better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VovK365pQ12G"
   },
   "outputs": [],
   "source": [
    "def pcshow(xs,ys,zs):\n",
    "    data=[go.Scatter3d(x=xs, y=ys, z=zs,\n",
    "                                   mode='markers')]\n",
    "    fig = visualize_rotate(data)\n",
    "    fig.update_traces(marker=dict(size=2,\n",
    "                      line=dict(width=2,\n",
    "                      color='DarkSlateGrey')),\n",
    "                      selector=dict(mode='markers'))\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6CRZdE2Qw5J"
   },
   "outputs": [],
   "source": [
    "#pcshow(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axdsyO0wWZEB"
   },
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tJZHWppZ85P"
   },
   "source": [
    "As we want it to look more like a real bed, let's write a function to sample points on the surface uniformly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pee3OqfyhSdt"
   },
   "source": [
    " ### Sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCgPQhfvh7R3"
   },
   "outputs": [],
   "source": [
    "class PointSampler(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, int)\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    def triangle_area(self, pt1, pt2, pt3):\n",
    "        side_a = np.linalg.norm(pt1 - pt2)\n",
    "        side_b = np.linalg.norm(pt2 - pt3)\n",
    "        side_c = np.linalg.norm(pt3 - pt1)\n",
    "        s = 0.5 * ( side_a + side_b + side_c)\n",
    "        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n",
    "\n",
    "    def sample_point(self, pt1, pt2, pt3):\n",
    "        # barycentric coordinates on a triangle\n",
    "        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
    "        s, t = sorted([random.random(), random.random()])\n",
    "        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n",
    "        return (f(0), f(1), f(2))\n",
    "        \n",
    "    \n",
    "    def __call__(self, mesh):\n",
    "        verts, faces = mesh\n",
    "        verts = np.array(verts)\n",
    "        areas = np.zeros((len(faces)))\n",
    "\n",
    "        for i in range(len(areas)):\n",
    "            areas[i] = (self.triangle_area(verts[faces[i][0]],\n",
    "                                           verts[faces[i][1]],\n",
    "                                           verts[faces[i][2]]))\n",
    "            \n",
    "        sampled_faces = (random.choices(faces, \n",
    "                                      weights=areas,\n",
    "                                      cum_weights=None,\n",
    "                                      k=self.output_size))\n",
    "        \n",
    "        sampled_points = np.zeros((self.output_size, 3))\n",
    "\n",
    "        for i in range(len(sampled_faces)):\n",
    "            sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n",
    "                                                   verts[sampled_faces[i][1]],\n",
    "                                                   verts[sampled_faces[i][2]]))\n",
    "        \n",
    "        return sampled_points\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xwg7LG6mkzgN"
   },
   "outputs": [],
   "source": [
    "#pointcloud = PointSampler(3000)((verts, faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "m5sSdqp-iTuA",
    "outputId": "573f58a9-d98d-4327-bbed-16a6361e72fd"
   },
   "outputs": [],
   "source": [
    "pcshow(*pointcloud.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5ZsXeLOrFTT"
   },
   "source": [
    "This pointcloud looks much more like a bed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXU9PdRqbbBx"
   },
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCduIRX6uiDs"
   },
   "source": [
    "Unit sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UR3r0WPdWbHN"
   },
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    def __call__(self, data):\n",
    "        pointcloud, properties = data[0], data[1]\n",
    "        assert len(pointcloud.shape)==2\n",
    "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0)\n",
    "        norm_factor = np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
    "        norm_pointcloud /= norm_factor\n",
    "        properties_norm = properties/norm_factor\n",
    "        #print(properties,properties_norm)\n",
    "\n",
    "        return  (norm_pointcloud, properties_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHr4mq4Fot5b"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlqQupcXhn1v"
   },
   "outputs": [],
   "source": [
    "dummy_properties = np.array([1.1, 2.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfMnH_o8aIWe"
   },
   "outputs": [],
   "source": [
    " norm_pointcloud,_ = Normalize()((pointcloud, dummy_properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "4fGlqqqjaQGF",
    "outputId": "b3ccd285-6e36-4c4a-c875-4fed853530f7"
   },
   "outputs": [],
   "source": [
    "pcshow(*norm_pointcloud.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTz_SFrDhezz"
   },
   "source": [
    "Notice that axis limits have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LtFfliNuxw3"
   },
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbYrmnasZAUg"
   },
   "source": [
    "Let's add *random rotation* of the whole pointcloud and random noise to its points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHAvoR7wuwS6"
   },
   "outputs": [],
   "source": [
    "class RandRotation_z(object):\n",
    "    def __call__(self, data):\n",
    "        pointcloud, properties = data[0], data[1]\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        theta = random.random() * 2. * math.pi\n",
    "        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
    "                               [ math.sin(theta),  math.cos(theta),    0],\n",
    "                               [0,                             0,      1]])\n",
    "        \n",
    "        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
    "        return  (rot_pointcloud, properties)\n",
    "    \n",
    "class RandomNoise(object):\n",
    "    def __call__(self, data):\n",
    "        pointcloud, properties = data[0], data[1]\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
    "    \n",
    "        noisy_pointcloud = pointcloud + noise\n",
    "        return  (noisy_pointcloud, properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aektc3DZwbc9"
   },
   "outputs": [],
   "source": [
    "rot_pointcloud, _ = RandRotation_z()((norm_pointcloud, dummy_properties))\n",
    "noisy_rot_pointcloud, _ = RandomNoise()((rot_pointcloud, dummy_properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "GcLIa7KmweAL",
    "outputId": "a123aafa-9dce-464a-f49d-28cbd74a5223"
   },
   "outputs": [],
   "source": [
    "pcshow(*noisy_rot_pointcloud.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE6QmxhRbwsY"
   },
   "source": [
    "### ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctHIvE-Kbr-m"
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, data):\n",
    "        pointcloud, properties = data[0], data[1]\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        return (torch.from_numpy(pointcloud).float(), torch.from_numpy(properties).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z7FK8nVrel4z",
    "outputId": "ba903e24-7318-4f4b-c971-faaa018ae085"
   },
   "outputs": [],
   "source": [
    "ToTensor()((noisy_rot_pointcloud, dummy_properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdQhWT4Q1GbF"
   },
   "outputs": [],
   "source": [
    "def default_transforms():\n",
    "    return transforms.Compose([\n",
    "                                Normalize(),\n",
    "                                ToTensor()\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMIT1MeNSSO8"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Sl3iM3CZM5n"
   },
   "source": [
    "Now we can create a [custom PyTorch Dataset](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i06OYFNR8fa_"
   },
   "outputs": [],
   "source": [
    "def parse_pipe_properties(element_data):\n",
    "  #target = [element_data['radius']/1000, element_data['length']/1000]\n",
    "  scaled_targets = [element_data['radius']/1000, element_data['length']/1000]\n",
    "  unscaled_targets = [element_data['direction'][0], element_data['direction'][1], element_data['direction'][2]]\n",
    "  #target = [element_data['radius']/1000]\n",
    "  return np.array(scaled_targets), np.array(unscaled_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUC_mouXRWvB"
   },
   "outputs": [],
   "source": [
    "# scaled properties must be transformed when the cloud's scale is transformed\n",
    "class PointCloudData(Dataset):\n",
    "    def __init__(self, root_dir, valid=False, folder=\"train\", category='pipe', transform=default_transforms()):\n",
    "        self.root_dir = root_dir\n",
    "        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
    "        self.category = category\n",
    "        self.transforms = transform if not valid else default_transforms()\n",
    "        metadata_file = open(root_dir/Path(category)/\"metadata_new.json\", 'r')\n",
    "        metadata = json.load(metadata_file)\n",
    "        self.valid = valid\n",
    "        self.files = []\n",
    "\n",
    "        new_dir = root_dir/Path(category)/folder\n",
    "        for file in os.listdir(new_dir):\n",
    "            if file.endswith('.pcd'):\n",
    "                sample = {}\n",
    "                sample['pcd_path'] = new_dir/file\n",
    "                sample['id'] = int(file.split(\".\")[0])\n",
    "                sample['scaled_properties'], sample['unscaled_properties'] = parse_pipe_properties(\n",
    "                    metadata[file.split(\".\")[0]])\n",
    "                self.files.append(sample)\n",
    "        self.targets = len(self.files[0]['scaled_properties']) + len(\n",
    "            self.files[0]['unscaled_properties'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __preproc__(self, file, properties):\n",
    "        cloud = read_pcd(file)\n",
    "        if self.transforms:\n",
    "            pointcloud, properties = self.transforms((cloud, properties))\n",
    "        return pointcloud, properties\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pcd_path = self.files[idx]['pcd_path']\n",
    "        scaled_properties = self.files[idx]['scaled_properties']\n",
    "        unscaled_properties = torch.from_numpy(self.files[idx]['unscaled_properties']).float()\n",
    "        id = self.files[idx]['id']\n",
    "        pointcloud, scaled_properties = self.__preproc__(pcd_path, scaled_properties)\n",
    "        return {'pointcloud': pointcloud, \n",
    "                'properties': torch.cat((scaled_properties, unscaled_properties)),\n",
    "                'id': id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOEaUDwzZY3v"
   },
   "source": [
    "Transforms for training. 1024 points per cloud as in the paper!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pOl95glmphX"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                    Normalize(),\n",
    "#                    RandomNoise(),\n",
    "                    ToTensor()\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpDsEx00mZrx"
   },
   "outputs": [],
   "source": [
    "train_ds = PointCloudData(path, transform=train_transforms)\n",
    "valid_ds = PointCloudData(path, valid=True, folder='test', transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arTK45IlBeiZ",
    "outputId": "7f8b0730-f00b-4a80-f8af-352f429e6d90"
   },
   "outputs": [],
   "source": [
    "print('Train dataset size: ', len(train_ds))\n",
    "print('Valid dataset size: ', len(valid_ds))\n",
    "#print('Number of classes: ', len(train_ds.classes))\n",
    "print('Sample pointcloud shape: ', train_ds[0]['pointcloud'])\n",
    "print('Sample pointcloud label: ', train_ds[0]['properties'])\n",
    "print('Sample pointcloud label: ', train_ds[0]['properties'])\n",
    "#print('Class: ', inv_classes[train_ds[0]['category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVGtKLa4PthS"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Isb_97zOA8Tl"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZV20opgrv23I"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Tnet(nn.Module):\n",
    "   def __init__(self, k=3):\n",
    "      super().__init__()\n",
    "      self.k=k\n",
    "      self.conv1 = nn.Conv1d(k,64,1)\n",
    "      self.conv2 = nn.Conv1d(64,128,1)\n",
    "      self.conv3 = nn.Conv1d(128,1024,1)\n",
    "      self.fc1 = nn.Linear(1024,512)\n",
    "      self.fc2 = nn.Linear(512,256)\n",
    "      self.fc3 = nn.Linear(256,k*k)\n",
    "\n",
    "      self.bn1 = nn.BatchNorm1d(64)\n",
    "      self.bn2 = nn.BatchNorm1d(128)\n",
    "      self.bn3 = nn.BatchNorm1d(1024)\n",
    "      self.bn4 = nn.BatchNorm1d(512)\n",
    "      self.bn5 = nn.BatchNorm1d(256)\n",
    "       \n",
    "\n",
    "   def forward(self, input):\n",
    "      # input.shape == (bs,n,3)\n",
    "      bs = input.size(0)\n",
    "      xb = F.relu(self.bn1(self.conv1(input)))\n",
    "      xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "      xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "      pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "      flat = nn.Flatten(1)(pool)\n",
    "      xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "      xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "      \n",
    "      #initialize as identity\n",
    "      init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "      if xb.is_cuda:\n",
    "        init=init.cuda()\n",
    "      matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "      return matrix\n",
    "\n",
    "\n",
    "class Transform(nn.Module):\n",
    "   def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = Tnet(k=3)\n",
    "        self.feature_transform = Tnet(k=64)\n",
    "        self.conv1 = nn.Conv1d(3,64,1)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "       \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "       \n",
    "   def forward(self, input):\n",
    "        matrix3x3 = self.input_transform(input)\n",
    "        # batch matrix multiplication\n",
    "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn1(self.conv1(xb)))\n",
    "\n",
    "        matrix64x64 = self.feature_transform(xb)\n",
    "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = self.bn3(self.conv3(xb))\n",
    "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        output = nn.Flatten(1)(xb)\n",
    "        return output, matrix3x3, matrix64x64\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, outputs = 2):\n",
    "        super().__init__()\n",
    "        self.transform = Transform()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, outputs)\n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        xb, matrix3x3, matrix64x64 = self.transform(input)\n",
    "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
    "        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
    "        output = self.fc3(xb)\n",
    "        return output, matrix3x3, matrix64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "580NErhyP1zD"
   },
   "outputs": [],
   "source": [
    "def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    bs=outputs.size(0)\n",
    "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
    "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n",
    "    if outputs.is_cuda:\n",
    "        id3x3=id3x3.cuda()\n",
    "        id64x64=id64x64.cuda()\n",
    "    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n",
    "    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n",
    "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mLBRcfwP2Sq"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUJOEaWdmsRD"
   },
   "source": [
    "You can find a pretrained model [here](https://drive.google.com/open?id=1nDG0maaqoTkRkVsOLtUAR9X3kn__LMSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvmmwhcePvt2",
    "outputId": "6474c32e-0bdf-4187-e9a3-7be891a6e864"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_DXKkfMPxP0"
   },
   "outputs": [],
   "source": [
    "targets = train_ds.targets\n",
    "pointnet = PointNet(outputs=targets)\n",
    "pointnet.to(device);\n",
    "#pointnet = pointnet.double()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ST7F9E5P0BI"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.005)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rg8obt6FP6Ff"
   },
   "outputs": [],
   "source": [
    "def train(model, savepath, targets, train_loader, val_loader=None,  epochs=25, save=True):\n",
    "    for epoch in range(epochs): \n",
    "        pointnet.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data['pointcloud'].to(device).float(), data['properties'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "\n",
    "            loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:    # print every 10 mini-batches\n",
    "                    print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n",
    "                        (epoch + 1, i + 1, len(train_loader), running_loss / 10))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        pointnet.eval()\n",
    "        total = 0\n",
    "\n",
    "        # validation\n",
    "        if val_loader:\n",
    "            with torch.no_grad():\n",
    "                total_val_loss = np.zeros(targets)\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data['pointcloud'].to(device).float(), data['properties'].to(device)\n",
    "                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "                    total += labels.size(0)\n",
    "                    for i in range(targets):\n",
    "                      val_loss = criterion(outputs[:,i], labels[:,i])\n",
    "                      total_val_loss[i] += val_loss.item()\n",
    "                    # _, predicted = torch.max(outputs.data, 1)\n",
    "                    # \n",
    "                    # correct += (predicted == labels).sum().item()\n",
    "            total_val_loss = total_val_loss / total\n",
    "            print('Valid loss: ', total_val_loss.tolist())\n",
    "\n",
    "        # save the model\n",
    "        if save:\n",
    "            torch.save(pointnet.state_dict(), savepath +\"save_\"+str(epoch)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-bPW3CKZaZ7",
    "outputId": "65e7494e-c83a-44e6-ce88-d89e6c2ae8bd"
   },
   "outputs": [],
   "source": [
    "train(pointnet, savepath, targets, train_loader, valid_loader,  save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8W4gOI_P9a9"
   },
   "source": [
    "## Test\n",
    "\n",
    "Analyze results statistically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pU70YWA7P-I_"
   },
   "outputs": [],
   "source": [
    "pointnet = PointNet(targets)\n",
    "#pointnet.load_state_dict(torch.load(savepath +'save_24.pth'))\n",
    "pointnet.load_state_dict(torch.load(savepath +'save_24.pth', map_location=torch.device('cpu')))\n",
    "pointnet.to(device);\n",
    "\n",
    "pointnet.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3m81wB8ZgQz",
    "outputId": "0cd835ae-1ab9-4457-9ce9-2429c087d9f5"
   },
   "outputs": [],
   "source": [
    "# check regression\n",
    "cloud_list = []\n",
    "label_list = []\n",
    "output_list = []\n",
    "predictions_list = []\n",
    "inputs_list = []\n",
    "id_list = []\n",
    "parameter_id = 0\n",
    "with torch.no_grad():\n",
    "    tot = 0\n",
    "    count = 0\n",
    "    for data in valid_loader:\n",
    "        inputs, labels, ids = data['pointcloud'].to(device).float(), data['properties'].to(device), data['id'].to(device)\n",
    "        outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "        print(data['pointcloud'].size(), labels.size(), outputs.size())\n",
    "\n",
    "        for i in range(outputs.size(0)):\n",
    "            label_list.append(labels[i][parameter_id].item())\n",
    "            id_list.append(ids[i].item())\n",
    "            output_list.append(outputs[i][parameter_id].item())\n",
    "            predictions_list.append(outputs[i].numpy())\n",
    "            inputs_list.append(labels[i].numpy())\n",
    "            cloud_list.append(inputs[i].numpy())\n",
    "            ratio = ((labels[i][parameter_id]-outputs[i][parameter_id])/labels[i][parameter_id]).item()\n",
    "            print('r', i+count, ids[i].item(), labels[i][parameter_id].item(), outputs[i][parameter_id].item(), ratio)\n",
    "            tot += np.absolute(ratio)\n",
    "            #print('l', labels[i][1].item(), outputs[i][1].item(), ((labels[i][1]-outputs[i][1])/labels[i][1]).item())\n",
    "        \n",
    "        count += outputs.size(0)\n",
    "    print(tot/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list, output_list, id_list = np.array(label_list), np.array(output_list), np.array(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = np.absolute((label_list - output_list)/label_list)\n",
    "ratio_ind = ratio.argsort()\n",
    "id_list = id_list[ratio_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id_list[-10:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cloud_id = 670 \n",
    "pcd_id = 18631   \n",
    "pcshow(*cloud_list[cloud_id].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save selected cloud\n",
    "# pcl = o3d.geometry.PointCloud()\n",
    "# pcl.points = o3d.utility.Vector3dVector(cloud_list[cloud_id])\n",
    "# o3d.io.write_point_cloud(\"cloud_\"+str(cloud_id)+\".pcd\", pcl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot error graph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "n, bins, _ = plt.hist(ratio, bins=np.arange(0,2,0.1))\n",
    "mid = 0.5*(bins[1:] + bins[:-1])\n",
    "plt.errorbar(mid, n, yerr=0.01, fmt='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_threshold = 0.2\n",
    "correct = ratio[np.where(ratio < error_threshold)]\n",
    "print(len(ratio), len(correct), len(correct)/len(ratio))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visually analyse predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize predictions side by side with ifc\n",
    "def visualize_predictions(cloud, element, preds, blueprint):\n",
    "    ifc = setup_ifc_file(blueprint)\n",
    "    owner_history = ifc.by_type(\"IfcOwnerHistory\")[0]\n",
    "    project = ifc.by_type(\"IfcProject\")[0]\n",
    "    context = ifc.by_type(\"IfcGeometricRepresentationContext\")[0]\n",
    "    floor = ifc.by_type(\"IfcBuildingStorey\")[0]\n",
    "\n",
    "    ifc_info = {\"owner_history\": owner_history,\n",
    "        \"project\": project,\n",
    "       \"context\": context, \n",
    "       \"floor\": floor}\n",
    "    \n",
    "    if element == 'pipe':\n",
    "        pm = {'r':preds[0], 'l':preds[1], 'd':[preds[2], preds[3], preds[4]] }\n",
    "        pm['p'] = [-((pm['l']*pm['d'][i])/2) for i in range(3)]\n",
    "        #print(pm)\n",
    "        \n",
    "        create_IfcPipe(pm['r'], pm['l'], pm['d'], pm['p'], ifc, ifc_info)\n",
    "        \n",
    "    elif element == 'elbow':\n",
    "        create_IfcElbow(pm['r'], pm['a'], pm['d'], pm['p'], pm['x'],\n",
    "                        pm['y'], pm['axis_dir'], ifc, ifc_info)\n",
    "    return vis_ifc_and_cloud(ifc,pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJvOTn3Bt1mR"
   },
   "outputs": [],
   "source": [
    "blueprint = 'data/sample.ifc'\n",
    "pcd_path = \"output/pipe/test/\" + str(pcd_id) + \".pcd\"\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "preds = predictions_list[cloud_id].tolist()\n",
    "inputs = inputs_list[cloud_id].tolist()\n",
    "print(preds)\n",
    "print(inputs)\n",
    "preds[0], preds[1] = preds[0]*500, preds[1]*500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = visualize_predictions(pcd, 'pipe', preds, blueprint)\n",
    "viewer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

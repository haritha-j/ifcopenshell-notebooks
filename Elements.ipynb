{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpvL68OfBEQC"
   },
   "source": [
    "# Element Parameter Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-z7n_pw4SMWl"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TJ47VNF7fmTS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "import datetime\n",
    "import logging\n",
    "import importlib\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "import scipy.spatial.distance\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ifcopenshell\n",
    "from utils.JupyterIFCRenderer import JupyterIFCRenderer\n",
    "from path import Path\n",
    "import open3d as o3d\n",
    "\n",
    "from src.elements import *\n",
    "from src.ifc import *\n",
    "from src. preparation import *\n",
    "from src.dataset import *\n",
    "from src.pointnet import *\n",
    "from src.visualisation import *\n",
    "from src.geometry import sq_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vpzTlKjmlr2q"
   },
   "outputs": [],
   "source": [
    "random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Xyu78RWIQEQJ"
   },
   "outputs": [],
   "source": [
    "#path = Path(\"ModelNet10\")\n",
    "#path = Path('/content/drive/MyDrive/ElementNet/')\n",
    "path = Path('output/')\n",
    "#savepath = '/content/drive/MyDrive/ElementNet/'\n",
    "savepath = 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddne6NHcPIHn"
   },
   "outputs": [],
   "source": [
    "f = path/\"tee/test/24102.pcd\"\n",
    "pointcloud = read_pcd(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Le4-KXs1j1E3",
    "outputId": "9a76b0dd-cc25-4535-99bd-74a0e5a27a6d"
   },
   "outputs": [],
   "source": [
    "len(pointcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axdsyO0wWZEB"
   },
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "m5sSdqp-iTuA",
    "outputId": "573f58a9-d98d-4327-bbed-16a6361e72fd"
   },
   "outputs": [],
   "source": [
    "pcshow(*pointcloud.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXU9PdRqbbBx"
   },
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_bbox(pointcloud)\n",
    "dummy_properties = np.array([1.1, 2.2])\n",
    "norm_pointcloud,_ = Normalize()((pointcloud, dummy_properties))\n",
    "pcshow(*norm_pointcloud.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LtFfliNuxw3"
   },
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbYrmnasZAUg"
   },
   "source": [
    "random rotation and random noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aektc3DZwbc9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rot_pointcloud, _ = RandRotation_z()((norm_pointcloud, dummy_properties))\n",
    "noisy_rot_pointcloud, _ = RandomNoise()((rot_pointcloud, dummy_properties))\n",
    "pcshow(*noisy_rot_pointcloud.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMIT1MeNSSO8"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOEaUDwzZY3v"
   },
   "source": [
    "Transforms for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4pOl95glmphX"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                    Normalize(),\n",
    "#                    RandomNoise(),\n",
    "                    ToTensor()\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xpDsEx00mZrx"
   },
   "outputs": [],
   "source": [
    "cat= 'tee'\n",
    "train_ds = PointCloudData(path, category=cat, transform=train_transforms)\n",
    "valid_ds = PointCloudData(path, valid=True, folder='test', category=cat, transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arTK45IlBeiZ",
    "outputId": "7f8b0730-f00b-4a80-f8af-352f429e6d90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  24102\n",
      "Valid dataset size:  2678\n",
      "Sample pointcloud shape:  tensor([[ 0.1303, -0.2685, -0.3857],\n",
      "        [ 0.4772,  0.0190,  0.1549],\n",
      "        [-0.0715, -0.0174, -0.4570],\n",
      "        ...,\n",
      "        [ 0.5441,  0.5830,  0.2189],\n",
      "        [-0.3477, -0.7637, -0.1173],\n",
      "        [-0.1770,  0.3757,  0.3679]])\n",
      "Sample pointcloud label:  tensor([ 0.3990,  1.6070,  0.3990,  0.8177, -0.1282, -0.1603, -0.1754,  0.4674,\n",
      "         0.8841,  0.5712,  0.8208,  0.5872,  0.8094, -0.1505,  0.9886, -0.6044,\n",
      "         0.7967,  0.6785,  0.7346])\n",
      "Sample pointcloud label:  tensor([ 0.3990,  1.6070,  0.3990,  0.8177, -0.1282, -0.1603, -0.1754,  0.4674,\n",
      "         0.8841,  0.5712,  0.8208,  0.5872,  0.8094, -0.1505,  0.9886, -0.6044,\n",
      "         0.7967,  0.6785,  0.7346])\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset size: ', len(train_ds))\n",
    "print('Valid dataset size: ', len(valid_ds))\n",
    "#print('Number of classes: ', len(train_ds.classes))\n",
    "print('Sample pointcloud shape: ', train_ds[0]['pointcloud'])\n",
    "print('Sample pointcloud label: ', train_ds[0]['properties'])\n",
    "print('Sample pointcloud label: ', train_ds[0]['properties'])\n",
    "#print('Class: ', inv_classes[train_ds[0]['category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cVGtKLa4PthS"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Isb_97zOA8Tl"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mLBRcfwP2Sq"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvmmwhcePvt2",
    "outputId": "6474c32e-0bdf-4187-e9a3-7be891a6e864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "l_DXKkfMPxP0"
   },
   "outputs": [],
   "source": [
    "input_size = 2048\n",
    "targets = train_ds.targets\n",
    "pointnet = PointNet(outputs=targets, input_size=input_size)\n",
    "pointnet.to(device);\n",
    "#pointnet = pointnet.double()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4ST7F9E5P0BI"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.005)\n",
    "criterion = torch.nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-bPW3CKZaZ7",
    "outputId": "65e7494e-c83a-44e6-ce88-d89e6c2ae8bd"
   },
   "outputs": [],
   "source": [
    "train(pointnet, savepath, optimizer, criterion, device, targets, train_loader, valid_loader, epochs=50, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8W4gOI_P9a9"
   },
   "source": [
    "## Test\n",
    "\n",
    "Analyze results statistically\n",
    "\n",
    "POINTNET++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data and model\n",
    "BASE_DIR = os.path.dirname(os.path.abspath('industrial-facility-relationships/'))\n",
    "BASE_DIR = os.path.join(BASE_DIR, 'pointnet2')\n",
    "ROOT_DIR = BASE_DIR\n",
    "sys.path.append(os.path.join(ROOT_DIR, 'models'))\n",
    "path = Path('output/')\n",
    "cat= 'tee'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_normals = False\n",
    "\n",
    "test_ds = PointCloudData(path, valid=True, folder='test', category=cat, transform=train_transforms)\n",
    "targets = train_ds.targets\n",
    "testDataLoader = torch.utils.data.DataLoader(dataset=test_ds, batch_size=64)\n",
    "test_criterion = nn.MSELoss()\n",
    "\n",
    "model_name = \"pointnet2_cls_ssg\"\n",
    "model_path = \"pointnet2/log/classification/pointnet2_cls_ssg/\"\n",
    "model = importlib.import_module(model_name)\n",
    "\n",
    "\n",
    "predictor = model.get_model(targets, normal_channel=use_normals)\n",
    "if device != \"cpu\":\n",
    "    predictor = predictor.cuda()\n",
    "\n",
    "    \n",
    "checkpoint = torch.load(model_path + '/checkpoints/best_model.pth')\n",
    "predictor.load_state_dict(checkpoint['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, device, criterion):\n",
    "    losses = []\n",
    "    predictor = model.eval()\n",
    "    cloud_list = []\n",
    "    label_list = []\n",
    "    output_list = []\n",
    "    predictions_list = []\n",
    "    inputs_list = []\n",
    "    id_list = []\n",
    "    parameter_id = 10\n",
    "    tot = 0\n",
    "    count = 0\n",
    "    \n",
    "    for j, data  in tqdm(enumerate(loader), total=len(loader)):\n",
    "        inputs, labels, ids = data['pointcloud'].to(device).float(), data['properties'].to(device), data['id'].to(device)\n",
    "\n",
    "        points, target, ids = data['pointcloud'].to(device).float(), data['properties'].to(device), data['id'].to(device)\n",
    "        points = points.transpose(2, 1)\n",
    "        outputs, _ = predictor(points)\n",
    "        outputs = outputs.to(torch.device('cpu'))\n",
    "        inputs = points.to(torch.device('cpu'))\n",
    "        labels = target.to(torch.device('cpu'))\n",
    "        ids = ids.to(torch.device('cpu'))\n",
    "        print(data['pointcloud'].size(), labels.size(), outputs.size())\n",
    "\n",
    "        for i in range(outputs.size(0)):\n",
    "            label_list.append(labels[i][parameter_id].item())\n",
    "            id_list.append(ids[i].item())\n",
    "            output_list.append(outputs[i][parameter_id].item())\n",
    "            predictions_list.append(outputs[i].numpy())\n",
    "            inputs_list.append(labels[i].numpy())\n",
    "            cloud_list.append(inputs[i].numpy())\n",
    "            ratio = ((labels[i][parameter_id]-outputs[i][parameter_id])/labels[i][parameter_id]).item()\n",
    "            print('r', i+count, ids[i].item(), labels[i][parameter_id].item(), outputs[i][parameter_id].item(), ratio)\n",
    "            tot += np.absolute(ratio)\n",
    "            #print('l', labels[i][1].item(), outputs[i][1].item(), ((labels[i][1]-outputs[i][1])/labels[i][1]).item())\n",
    "        \n",
    "        count += outputs.size(0)\n",
    "    print(tot/count)        \n",
    "\n",
    "    return predictions_list, inputs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfb664a97e644cfaefad11a2e8c0bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predictions_list, inputs_list = test(predictor.eval(), testDataLoader, device, test_criterion)\n",
    "    \n",
    "print(len(predictions_list), len(inputs_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORIGINAL POINTNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pU70YWA7P-I_"
   },
   "outputs": [],
   "source": [
    "# pointnet = PointNet(targets, input_size)\n",
    "# #pointnet.load_state_dict(torch.load(savepath +'save_24.pth'))\n",
    "# pointnet.load_state_dict(torch.load(savepath +'save_49.pth', map_location=torch.device('cpu')))\n",
    "# pointnet.to(device);\n",
    "\n",
    "# pointnet.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3m81wB8ZgQz",
    "outputId": "0cd835ae-1ab9-4457-9ce9-2429c087d9f5"
   },
   "outputs": [],
   "source": [
    "# # check regression\n",
    "# cloud_list = []\n",
    "# label_list = []\n",
    "# output_list = []\n",
    "# predictions_list = []\n",
    "# inputs_list = []\n",
    "# id_list = []\n",
    "# parameter_id = 10\n",
    "# with torch.no_grad():\n",
    "#     tot = 0\n",
    "#     count = 0\n",
    "#     for data in valid_loader:\n",
    "#         inputs, labels, ids = data['pointcloud'].to(device).float(), data['properties'].to(device), data['id'].to(device)\n",
    "#         outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "#         outputs = outputs.to(torch.device('cpu'))\n",
    "#         inputs = inputs.to(torch.device('cpu'))\n",
    "#         labels = labels.to(torch.device('cpu'))\n",
    "#         ids = ids.to(torch.device('cpu'))\n",
    "#         print(data['pointcloud'].size(), labels.size(), outputs.size())\n",
    "\n",
    "#         for i in range(outputs.size(0)):\n",
    "#             label_list.append(labels[i][parameter_id].item())\n",
    "#             id_list.append(ids[i].item())\n",
    "#             output_list.append(outputs[i][parameter_id].item())\n",
    "#             predictions_list.append(outputs[i].numpy())\n",
    "#             inputs_list.append(labels[i].numpy())\n",
    "#             cloud_list.append(inputs[i].numpy())\n",
    "#             ratio = ((labels[i][parameter_id]-outputs[i][parameter_id])/labels[i][parameter_id]).item()\n",
    "#             print('r', i+count, ids[i].item(), labels[i][parameter_id].item(), outputs[i][parameter_id].item(), ratio)\n",
    "#             tot += np.absolute(ratio)\n",
    "#             #print('l', labels[i][1].item(), outputs[i][1].item(), ((labels[i][1]-outputs[i][1])/labels[i][1]).item())\n",
    "        \n",
    "#         count += outputs.size(0)\n",
    "#     print(tot/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate direction / position error\n",
    "def error_calc(predictions_list, inputs_list, k, j, direction = True, use_direction = False, square_error=True):\n",
    "\n",
    "    total_error = 0\n",
    "    for i, pr in enumerate(predictions_list):\n",
    "        if direction:\n",
    "            if use_direction:\n",
    "                pred = get_direction_from_trig(pr, k) \n",
    "                y = get_direction_from_trig(inputs_list[i], k)\n",
    "            else:\n",
    "                pred = get_direction_from_position(pr, k, j)\n",
    "                y = get_direction_from_position(inputs_list[i], k, j)\n",
    "            \n",
    "        else:\n",
    "            pred = [pr[k], pr[k+1], pr[k+2]]\n",
    "            y = [inputs_list[i][k], inputs_list[i][k+1], inputs_list[i][k+2]]\n",
    "        if square_error:\n",
    "            total_error += sq_distance(pred[0], pred[1], pred[2], \n",
    "                                      y[0], y[1], y[2])\n",
    "        else:\n",
    "            #angle error\n",
    "            total_error += math.degrees(math.acos(np.dot(pred, y)))\n",
    "            #print('mag', math.degrees(math.acos(np.dot(pred, y))))\n",
    "    print(total_error/len(predictions_list), len(predictions_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 7\n",
    "j = 4\n",
    "direction = True\n",
    "use_direction = True\n",
    "square_error = True\n",
    "error_calc(predictions_list, inputs_list, k, j, direction, use_direction, square_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list, output_list, id_list = np.array(label_list), np.array(output_list), np.array(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = np.absolute((label_list - output_list)/label_list)\n",
    "ratio_ind = ratio.argsort()\n",
    "id_list = id_list[ratio_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id_list[-10:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cloud_id = 0\n",
    "pcd_id = 24132                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot error graph\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "ratio_neg = (label_list - output_list)/label_list\n",
    "n, bins, _ = plt.hist(ratio_neg, bins=np.arange(-2,2,0.02))\n",
    "mid = 0.5*(bins[1:] + bins[:-1])\n",
    "plt.errorbar(mid, n, yerr=0.01, fmt='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_threshold = 0.1\n",
    "correct = ratio[np.where(ratio < error_threshold)]\n",
    "print(len(ratio), len(correct), len(correct)/len(ratio))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visually analyse predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJvOTn3Bt1mR"
   },
   "outputs": [],
   "source": [
    "scale_factor = 1000\n",
    "blueprint = 'data/sample.ifc'\n",
    "pcd_path = \"output/\" + cat + \"/test/\" + str(pcd_id) + \".pcd\"\n",
    "\n",
    "# load pcd and 'un-normalise'\n",
    "pcd_temp = o3d.io.read_point_cloud(pcd_path).points\n",
    "norm_pcd_temp = np.mean(pcd_temp, axis=0)\n",
    "norm_factor = np.max(np.linalg.norm((pcd_temp), axis=1))\n",
    "points = cloud_list[cloud_id]*norm_factor + norm_pcd_temp\n",
    "pcd = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "preds = predictions_list[cloud_id].tolist()\n",
    "inputs = inputs_list[cloud_id].tolist()\n",
    "print(preds)\n",
    "print(inputs)\n",
    "\n",
    "# scale predictions when necessary\n",
    "if cat == 'pipe':\n",
    "    scalable_targets = [0,1]\n",
    "elif cat == 'elbow':  \n",
    "    scalable_targets = [0,1,2]\n",
    "elif cat == 'tee':\n",
    "    scalable_targets = [0,1,2,3]\n",
    "\n",
    "for i in scalable_targets:\n",
    "    preds[i] = preds[i]*scale_factor*norm_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "viewer, ifc = visualize_predictions(pcd, cat, preds, blueprint, visualize=True)\n",
    "viewer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICP finetuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point sampling\n",
    "\n",
    "# save ifc\n",
    "ifc.write('output_ifc.ifc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = o3d.io.read_point_cloud(demo_icp_pcds.paths[0])\n",
    "target = o3d.io.read_point_cloud(demo_icp_pcds.paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# icp fitting\n",
    "\n",
    "import copy\n",
    "# path = 'output/elbow/test/'\n",
    "# source = o3d.io.read_point_cloud(path + \"17433.pcd\")\n",
    "# target = o3d.io.read_point_cloud(path + \"17433.pcd\")\n",
    "\n",
    "demo_icp_pcds = o3d.data.DemoICPPointClouds()\n",
    "source = o3d.io.read_point_cloud(demo_icp_pcds.paths[0])\n",
    "target = o3d.io.read_point_cloud(demo_icp_pcds.paths[1])\n",
    "\n",
    "threshold = 0.02\n",
    "trans_init = np.asarray([[0.862, 0.011, -0.507, 0.5],\n",
    "                         [-0.139, 0.967, -0.215, 0.7],\n",
    "                         [0.487, 0.255, 0.835, -1.4], [0.0, 0.0, 0.0, 1.0]])\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "#     o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "#                                       zoom=0.4459,\n",
    "#                                       front=[0.9288, -0.2951, -0.2242],\n",
    "#                                       lookat=[1.6784, 2.0612, 1.4451],\n",
    "#                                       up=[-0.3402, -0.9189, -0.1996])\n",
    "    o3d.io.write_point_cloud(\"src.pcd\", source_temp)\n",
    "    o3d.io.write_point_cloud(\"target.pcd\", target_temp)\n",
    "    \n",
    "    \n",
    "def icp(source, target, threshold, trans_init):\n",
    "\n",
    "    #draw_registration_result(source, target, trans_init)\n",
    "    print(\"Initial alignment\")\n",
    "    evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "        source, target, threshold, trans_init)\n",
    "    print(evaluation)\n",
    "\n",
    "    print(\"Apply point-to-point ICP\")\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, trans_init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    print(reg_p2p)\n",
    "    print(\"Transformation is:\")\n",
    "    print(reg_p2p.transformation)\n",
    "    print(\"\")\n",
    "    draw_registration_result(source, target, reg_p2p.transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# icp(source, target, threshold, trans_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesh deformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
